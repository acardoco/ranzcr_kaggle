{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022477,
     "end_time": "2021-01-31T14:21:47.713341",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.690864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.762708Z",
     "iopub.status.busy": "2021-01-31T14:21:47.761882Z",
     "iopub.status.idle": "2021-01-31T14:21:47.765190Z",
     "shell.execute_reply": "2021-01-31T14:21:47.764519Z"
    },
    "papermill": {
     "duration": 0.029226,
     "end_time": "2021-01-31T14:21:47.765360",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.736134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install -q pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (1.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.26.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.55.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.10.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 3.4 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.10-py3-none-any.whl size=73268 sha256=a47f0114539f642ababb68d15f9f95f768e402af08dd6226564763a25182287d\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/c5/fe/7e7fb5b3d1f150fac96188949b3d83d375a4c9df16ba557e52\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.5.10\n",
      "    Uninstalling kaggle-1.5.10:\n",
      "      Successfully uninstalled kaggle-1.5.10\n",
      "Successfully installed kaggle-1.5.10\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle # force install the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ~/.kaggle\n",
    "# ! cp kaggle/kaggle.json ~/.kaggle/\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster to work with, but you have to repeat the process every time you instantiate the runtime.\n",
    "# ! kaggle competitions download -c ranzcr-clip-catheter-line-classification \n",
    "# ! unzip ranzcr-clip-catheter-line-classification.zip\n",
    "\n",
    "# Alternatively, you can download to your Drive, and then access accordingly.\n",
    "# This can cause issues as Drive is notoriously slow / poor at indexing large directories (https://stackoverflow.com/questions/54294532/time-out-on-drive-mount-content-drive-in-google-colab)\n",
    "# ! mkdir /content/gdrive/MyDrive/ranzcr\n",
    "# ! kaggle competitions download -c ranzcr-clip-catheter-line-classification -p /content/gdrive/MyDrive/ranzcr\n",
    "# ! unzip /content/gdrive/MyDrive/ranzcr/ranzcr-clip-catheter-line-classification.zip\n",
    "\n",
    "# For file paths, you'll now be using, for example:\n",
    "TRAIN_DIR = '/content/train' # or '//content/gdrive/MyDrive/ranzcr/train' if you decide to go with Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.812994Z",
     "iopub.status.busy": "2021-01-31T14:21:47.812199Z",
     "iopub.status.idle": "2021-01-31T14:21:47.814853Z",
     "shell.execute_reply": "2021-01-31T14:21:47.815353Z"
    },
    "papermill": {
     "duration": 0.029416,
     "end_time": "2021-01-31T14:21:47.815561",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.786145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# TRAIN_PATH = 'gs://ranzcr-data/'\n",
    "TRAIN_PATH = '/train/'\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "client = storage.Client()\n",
    "source_bucket_imagenes = client.get_bucket('ranzcr-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021214,
     "end_time": "2021-01-31T14:21:47.857979",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.836765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.912993Z",
     "iopub.status.busy": "2021-01-31T14:21:47.912226Z",
     "iopub.status.idle": "2021-01-31T14:21:47.915050Z",
     "shell.execute_reply": "2021-01-31T14:21:47.915569Z"
    },
    "papermill": {
     "duration": 0.036682,
     "end_time": "2021-01-31T14:21:47.915747",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.879065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    device='GPU' # ['TPU', 'GPU']\n",
    "    nprocs = 1 # [1, 8]\n",
    "    print_freq=100\n",
    "    num_workers = 4\n",
    "    model_name='resnet200d_320' # \n",
    "    size = 512\n",
    "    scheduler='ReduceLROnPlateau' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs = 10\n",
    "    factor=0.1 # ReduceLROnPlateau. 0.2\n",
    "    patience=0 # ReduceLROnPlateau. 4\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=5 # CosineAnnealingLR. 4\n",
    "    T_0 = 4 # CosineAnnealingWarmRestarts\n",
    "    lr= 5e-4 # 1e-4, 5e-4 para step 2\n",
    "    min_lr= 1e-6\n",
    "    batch_size= 24 # 24\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=666\n",
    "    target_size=11\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                 'Swan Ganz Catheter Present']\n",
    "    n_fold=5\n",
    "    trn_fold=[0] # [0, 1, 2, 3, 4]. \n",
    "    train=True\n",
    "    USE_TEST_FOLD = True\n",
    "    CURRENT_FOLD = 0\n",
    "    WARMUP = 10\n",
    "    STEP = 0 # 0 sin annotaciones, 1, 2 y 3\n",
    "    # step 2\n",
    "    weights=[0.5, 1]\n",
    "    teacher = '../input/resnet200d-step1-teachers/'\n",
    "    # step 3\n",
    "    student = '../input/resnet200-step2-students/'\n",
    "    # MORE LAYERS: DenseSigmoid, BatchNorm y PReLU\n",
    "    MORE_LAYERS_MODEL = False\n",
    "    student_more_layers = '../input/resnet200dstudentsstep2/'\n",
    "    # TODO para continuar entrenando\n",
    "    CONTINUE_TRAINING = False\n",
    "    continue_path = '../input/resnet200dstep3morelayersphase1/'\n",
    "    lr_continue = 5e-5 # CAMBIAR A MANO\n",
    "    # OTROS TIPOS DE MODELOS\n",
    "    DO_EFFICIENT = False\n",
    "    effnet_path = '../input/efficientnet-pytorch/'\n",
    "    # SERESNET152D\n",
    "    DO_SERESNET152D = False\n",
    "    \n",
    "# correciones\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    \n",
    "if CFG.CONTINUE_TRAINING:\n",
    "    CFG.epochs = 14\n",
    "    CFG.lr = CFG.lr_continue\n",
    "    \n",
    "if CFG.MORE_LAYERS_MODEL:\n",
    "    CFG.student = CFG.student_more_layers\n",
    "    \n",
    "if CFG.STEP == 3:\n",
    "    CFG.USE_TEST_FOLD = True\n",
    "    \n",
    "if CFG.DO_SERESNET152D:\n",
    "    CFG.model_name = 'seresnet152d_320'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.971323Z",
     "iopub.status.busy": "2021-01-31T14:21:47.970633Z",
     "iopub.status.idle": "2021-01-31T14:22:00.450231Z",
     "shell.execute_reply": "2021-01-31T14:22:00.448595Z"
    },
    "papermill": {
     "duration": 12.512386,
     "end_time": "2021-01-31T14:22:00.450394",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.938008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    os.system('curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py')\n",
    "    os.system('python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev')\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.batch_size = CFG.batch_size // CFG.nprocs\n",
    "    \n",
    "if CFG.DO_EFFICIENT:\n",
    "    !pip install efficientnet_pytorch\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    CFG.lr = 3e-3\n",
    "    CFG.model_name = \"efficientnet-b7\"\n",
    "    #CFG.size= 600\n",
    "    CFG.epochs = 10 \n",
    "    if CFG.device == 'GPU':\n",
    "        CFG.batch_size = 8\n",
    "    if CFG.device == 'TPU':\n",
    "        CFG.batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.3.4-py3-none-any.whl (244 kB)\n",
      "\u001b[K     |████████████████████████████████| 244 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.3.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026861,
     "end_time": "2021-01-31T14:22:00.506625",
     "exception": false,
     "start_time": "2021-01-31T14:22:00.479764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:00.574792Z",
     "iopub.status.busy": "2021-01-31T14:22:00.573923Z",
     "iopub.status.idle": "2021-01-31T14:22:03.844914Z",
     "shell.execute_reply": "2021-01-31T14:22:03.843741Z"
    },
    "papermill": {
     "duration": 3.311409,
     "end_time": "2021-01-31T14:22:03.845102",
     "exception": false,
     "start_time": "2021-01-31T14:22:00.533693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('gs://extras-entrenamiento/pytorch_image_models')\n",
    "sys.path.append('gs://extras-entrenamiento/timm')\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "# from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "import albumentations\n",
    "from albumentations import *\n",
    "\n",
    "import timm\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026475,
     "end_time": "2021-01-31T14:22:03.899542",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.873067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:03.961251Z",
     "iopub.status.busy": "2021-01-31T14:22:03.960310Z",
     "iopub.status.idle": "2021-01-31T14:22:03.970184Z",
     "shell.execute_reply": "2021-01-31T14:22:03.969624Z"
    },
    "papermill": {
     "duration": 0.04609,
     "end_time": "2021-01-31T14:22:03.970312",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.924222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025661,
     "end_time": "2021-01-31T14:22:04.021054",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.995393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.077687Z",
     "iopub.status.busy": "2021-01-31T14:22:04.077061Z",
     "iopub.status.idle": "2021-01-31T14:22:04.378228Z",
     "shell.execute_reply": "2021-01-31T14:22:04.378845Z"
    },
    "papermill": {
     "duration": 0.332513,
     "end_time": "2021-01-31T14:22:04.379053",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.046540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds are:  [0, 1, 2, 3, 4]\n",
      "Selected folds are:  [0]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('gs://extras-entrenamiento/train_folds.csv')\n",
    "dfx = pd.read_csv('gs://extras-entrenamiento/train_folds.csv')\n",
    "train_annotations = pd.read_csv('gs://extras-entrenamiento/train_annotations.csv')\n",
    "\n",
    "print(\"Folds are: \", sorted(dfx.fold.unique()))\n",
    "print(\"Selected folds are: \", CFG.trn_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024139,
     "end_time": "2021-01-31T14:22:04.428196",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.404057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.503284Z",
     "iopub.status.busy": "2021-01-31T14:22:04.501667Z",
     "iopub.status.idle": "2021-01-31T14:22:04.504490Z",
     "shell.execute_reply": "2021-01-31T14:22:04.505012Z"
    },
    "papermill": {
     "duration": 0.049967,
     "end_time": "2021-01-31T14:22:04.505157",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.455190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "COLOR_MAP = {'ETT - Abnormal': (255, 0, 0),\n",
    "             'ETT - Borderline': (0, 255, 0),\n",
    "             'ETT - Normal': (0, 0, 255),\n",
    "             'NGT - Abnormal': (255, 255, 0),\n",
    "             'NGT - Borderline': (255, 0, 255),\n",
    "             'NGT - Incompletely Imaged': (0, 255, 255),\n",
    "             'NGT - Normal': (128, 0, 0),\n",
    "             'CVC - Abnormal': (0, 128, 0),\n",
    "             'CVC - Borderline': (0, 0, 128),\n",
    "             'CVC - Normal': (128, 128, 0),\n",
    "             'Swan Ganz Catheter Present': (128, 0, 128),\n",
    "            }\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, df_annotations, annot_size=50, transform=None, use_annot=False):\n",
    "        self.df = df\n",
    "        self.df_annotations = df_annotations\n",
    "        self.use_annot = use_annot\n",
    "        self.annot_size = annot_size\n",
    "        self.file_names = df['StudyInstanceUID'].values\n",
    "        self.labels = df[CFG.target_cols].values\n",
    "        self.transform = transform\n",
    "        self.shape = df.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = file_name + '.jpg'\n",
    "        image = cv2.imread(file_path)\n",
    "#         source_blob = source_bucket_imagenes.get_blob(file_path)\n",
    "#         image = np.asarray(bytearray(source_blob.download_as_string()), dtype=\"uint8\")\n",
    "#         image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = torch.tensor(self.labels[idx]).float()\n",
    "        # annotated imageç\n",
    "        # STEP 1 o 2\n",
    "        if CFG.STEP > 0 and CFG.STEP < 3:\n",
    "            #STEP 2\n",
    "            if CFG.STEP == 2 and self.use_annot:\n",
    "                image_annot = image.copy()\n",
    "            query_string = f\"StudyInstanceUID == '{file_name}'\"\n",
    "            df = self.df_annotations.query(query_string)\n",
    "            for i, row in df.iterrows():\n",
    "                label = row[\"label\"]\n",
    "                data = np.array(ast.literal_eval(row[\"data\"]))\n",
    "                for d in data:\n",
    "                    # STEP 2\n",
    "                    if CFG.STEP == 2 and self.use_annot:\n",
    "                        image_annot[d[1]-self.annot_size//2:d[1]+self.annot_size//2,\n",
    "                                d[0]-self.annot_size//2:d[0]+self.annot_size//2,\n",
    "                                :] = COLOR_MAP[label]\n",
    "                    # STEP 1\n",
    "                    else:\n",
    "                        image[d[1]-self.annot_size//2:d[1]+self.annot_size//2,\n",
    "                              d[0]-self.annot_size//2:d[0]+self.annot_size//2,\n",
    "                              :] = COLOR_MAP[label]\n",
    "        # aplicar transform\n",
    "        if CFG.STEP == 2 and self.use_annot:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, image_annot=image_annot)\n",
    "                image = augmented['image']\n",
    "                image_annot = augmented['image_annot']\n",
    "            return image, image_annot, labels\n",
    "        else:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "            return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025151,
     "end_time": "2021-01-31T14:22:04.555809",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.530658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.626582Z",
     "iopub.status.busy": "2021-01-31T14:22:04.619316Z",
     "iopub.status.idle": "2021-01-31T14:22:04.629187Z",
     "shell.execute_reply": "2021-01-31T14:22:04.628729Z"
    },
    "papermill": {
     "duration": 0.048509,
     "end_time": "2021-01-31T14:22:04.629307",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.580798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "# def get_transforms(*, data):\n",
    "    \n",
    "#     if data == 'train':\n",
    "#         return Compose([\n",
    "#            albumentations.RandomResizedCrop(CFG.size, CFG.size, scale=(0.9, 1), p=1), \n",
    "#            albumentations.HorizontalFlip(p=0.5),\n",
    "#            albumentations.ShiftScaleRotate(p=0.5),\n",
    "#            albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n",
    "#            albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "#            albumentations.CLAHE(clip_limit=(1,4), p=0.5),\n",
    "#            albumentations.OneOf([\n",
    "#                albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "#                albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "#                albumentations.ElasticTransform(alpha=3),\n",
    "#            ], p=0.2),\n",
    "#            albumentations.OneOf([\n",
    "#                albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "#                albumentations.GaussianBlur(),\n",
    "#                albumentations.MotionBlur(),\n",
    "#                albumentations.MedianBlur(),\n",
    "#            ], p=0.2),\n",
    "#           albumentations.Resize(CFG.size, CFG.size),\n",
    "#           albumentations.OneOf([\n",
    "#               JpegCompression(),\n",
    "#               Downscale(scale_min=0.1, scale_max=0.15),\n",
    "#           ], p=0.2),\n",
    "#           IAAPiecewiseAffine(p=0.2),\n",
    "#           IAASharpen(p=0.2),\n",
    "#           albumentations.Cutout(max_h_size=int(CFG.size * 0.1), max_w_size=int(CFG.size * 0.1), num_holes=5, p=0.5),\n",
    "#           albumentations.Normalize(),\n",
    "#         ToTensorV2(),\n",
    "#         ])\n",
    "\n",
    "#     elif data == 'valid':\n",
    "#         return Compose([\n",
    "#             albumentations.Resize(CFG.size, CFG.size),\n",
    "#            albumentations.Normalize(),\n",
    "#         ToTensorV2(),\n",
    "#         ])\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "def get_transforms_step2(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ], additional_targets={'image_annot': 'image'})\n",
    "    \n",
    "    elif data == 'check':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            #Normalize(\n",
    "            #    mean=[0.485, 0.456, 0.406],\n",
    "            #    std=[0.229, 0.224, 0.225],\n",
    "            #),\n",
    "            ToTensorV2(),\n",
    "        ], additional_targets={'image_annot': 'image'})\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.684244Z",
     "iopub.status.busy": "2021-01-31T14:22:04.683663Z",
     "iopub.status.idle": "2021-01-31T14:22:04.687899Z",
     "shell.execute_reply": "2021-01-31T14:22:04.687443Z"
    },
    "papermill": {
     "duration": 0.033824,
     "end_time": "2021-01-31T14:22:04.688024",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.654200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30083, 15)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-eeea05bc6294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'label: {label}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2212a9f93d79>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         image = np.asarray(bytearray(source_blob.download_as_string()), dtype=\"uint8\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#         image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# annotated imageç\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# annotated\n",
    "if CFG.STEP == 1:\n",
    "    train_dataset = TrainDataset(dfx[dfx['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True),\n",
    "                             df_annotations = train_annotations, transform = None)\n",
    "elif CFG.STEP == 2:\n",
    "    train_dataset = TrainDataset(dfx[dfx['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True),\n",
    "                             df_annotations = train_annotations, transform=get_transforms_step2(data='check'), use_annot=True)\n",
    "else:\n",
    "    train_dataset = TrainDataset(dfx, df_annotations = train_annotations, transform=None)\n",
    "    \n",
    "print(train_dataset.shape)\n",
    "\n",
    "for i in range(5):\n",
    "    if CFG.STEP == 2:\n",
    "        image, image_annot, label = train_dataset[i]\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image.transpose(0, 1).transpose(1, 2))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image_annot.transpose(0, 1).transpose(1, 2))\n",
    "        plt.title(f'label: {label}')\n",
    "        plt.show() \n",
    "    else:\n",
    "        image, label = train_dataset[i]\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'label: {label}')\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source_blob = source_bucket_imagenes.get_blob('1.2.826.0.1.3680043.8.498.10001065121843652267743449160233082683.jpg')\n",
    "# image = np.asarray(bytearray(source_blob.download_as_string()), dtype=\"uint8\")\n",
    "# image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# # image = cv2.imread('gs://ranzcr-data/1.2.826.0.1.3680043.8.498.10001065121843652267743449160233082683.jpg')\n",
    "# # image = io.imread('https://storage.cloud.google.com/ranzcr-data/1.2.826.0.1.3680043.8.498.10001065121843652267743449160233082683.jpg?authuser=1')\n",
    "# plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024985,
     "end_time": "2021-01-31T14:22:04.738007",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.713022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.807210Z",
     "iopub.status.busy": "2021-01-31T14:22:04.805309Z",
     "iopub.status.idle": "2021-01-31T14:22:04.808023Z",
     "shell.execute_reply": "2021-01-31T14:22:04.808585Z"
    },
    "papermill": {
     "duration": 0.045842,
     "end_time": "2021-01-31T14:22:04.808756",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.762914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL RESNET 200D\n",
    "# ====================================================\n",
    "class CustomResNet200D(nn.Module):\n",
    "    def __init__(self, model_name='resnet200d_320', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        if pretrained:\n",
    "            pretrained_path = 'gs://extras-entrenamiento/resnet200d_ra2-bdba9bf9.pth'\n",
    "#             self.model.load_state_dict(torch.load(pretrained_path))\n",
    "            print(f'load {model_name} pretrained model')\n",
    "        n_features = self.model.fc.in_features # son 2048\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            self.sigmoid_fc = nn.Linear(in_features=n_features, out_features=512)\n",
    "            self.bs = nn.BatchNorm1d(num_features = 512)\n",
    "            self.prelu = nn.PReLU()\n",
    "            self.fc = nn.Linear(512, CFG.target_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            output = F.sigmoid(self.sigmoid_fc(pooled_features))\n",
    "            output = self.bs(output)\n",
    "            output = self.prelu(output)\n",
    "            output = self.fc(output) #output pooled_features\n",
    "        else:\n",
    "            output = self.fc(pooled_features)\n",
    "        # features, _, y_preds\n",
    "        return features, pooled_features, output\n",
    "    \n",
    "    \n",
    "# ====================================================\n",
    "# MODEL EFFICIENT B7\n",
    "# ====================================================\n",
    "class CustomEfficientB7(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet-b7', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.effnet = EfficientNet.from_pretrained(model_name) \n",
    "        n_features = self.effnet._fc.in_features\n",
    "#         self.effnet._conv_stem.in_channels = 1\n",
    "#         weight = self.effnet._conv_stem.weight.mean(1, keepdim=True)\n",
    "#         self.effnet._conv_stem.weight = torch.nn.Parameter(weight)\n",
    "        self.effnet._fc = nn.Identity()\n",
    "        \n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            self.sigmoid_fc = nn.Linear(in_features=n_features, out_features=512)\n",
    "            self.bs = nn.BatchNorm1d(num_features = 512)\n",
    "            self.prelu = nn.PReLU()\n",
    "            self.out = nn.Linear(512, CFG.target_size)\n",
    "        else:\n",
    "            self.out = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size = image.size(0)\n",
    "    \n",
    "        x = self.effnet.extract_features(image)\n",
    "        pooled_features = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            output = F.sigmoid(self.sigmoid_fc(pooled_features))\n",
    "            output = self.bs(output)\n",
    "            output = self.prelu(output)\n",
    "            output = self.out(output)\n",
    "        else:\n",
    "            output = self.out(pooled_features)\n",
    "        # features, _, y_preds\n",
    "        return x, pooled_features, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024307,
     "end_time": "2021-01-31T14:22:04.857819",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.833512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Funcion Loss para step 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.914593Z",
     "iopub.status.busy": "2021-01-31T14:22:04.912893Z",
     "iopub.status.idle": "2021-01-31T14:22:04.915248Z",
     "shell.execute_reply": "2021-01-31T14:22:04.915725Z"
    },
    "papermill": {
     "duration": 0.033285,
     "end_time": "2021-01-31T14:22:04.915859",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.882574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1]):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "        \n",
    "    def forward(self, teacher_features, features, y_pred, labels):\n",
    "        consistency_loss = nn.MSELoss()(teacher_features.view(-1), features.view(-1))\n",
    "        cls_loss = nn.BCEWithLogitsLoss()(y_pred, labels)\n",
    "        loss = self.weights[0] * consistency_loss + self.weights[1] * cls_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025491,
     "end_time": "2021-01-31T14:22:04.966985",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.941494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.042740Z",
     "iopub.status.busy": "2021-01-31T14:22:05.027020Z",
     "iopub.status.idle": "2021-01-31T14:22:05.056340Z",
     "shell.execute_reply": "2021-01-31T14:22:05.055837Z"
    },
    "papermill": {
     "duration": 0.063807,
     "end_time": "2021-01-31T14:22:05.056495",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.992688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "# https://www.kaggle.com/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n",
    "# class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "#     def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "#         super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "#     def get_lr(self):\n",
    "#         if self.last_epoch > self.total_epoch:\n",
    "#             if self.after_scheduler:\n",
    "#                 if not self.finished:\n",
    "#                     self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "#                     self.finished = True\n",
    "#                 return self.after_scheduler.get_lr()\n",
    "#             return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "#         if self.multiplier == 1.0:\n",
    "#             return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "#         else:\n",
    "#             return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                _, _, y_preds = model(images)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "        elif CFG.device == 'TPU':\n",
    "            _, _, y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "#                       'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "#                        lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                xm.master_print('Epoch: [{0}][{1}/{2}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                'Grad: {grad_norm:.4f}  '\n",
    "#                                 'LR: {lr:.6f}  '\n",
    "                                .format(\n",
    "                                epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                                grad_norm=grad_norm,\n",
    "#                                 lr=scheduler.get_lr()[0],\n",
    "                                ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            _, _, y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      .format(\n",
    "                       step, len(valid_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                xm.master_print('EVAL: [{0}/{1}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                .format(\n",
    "                                step, len(valid_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                                ))\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.129144Z",
     "iopub.status.busy": "2021-01-31T14:22:05.121767Z",
     "iopub.status.idle": "2021-01-31T14:22:05.131690Z",
     "shell.execute_reply": "2021-01-31T14:22:05.131173Z"
    },
    "papermill": {
     "duration": 0.049606,
     "end_time": "2021-01-31T14:22:05.131816",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.082210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************************************************************\n",
    "# **************************************** FOR STEP 2 ************************************************\n",
    "# ****************************************************************************************************\n",
    "def train_fn_step2(train_loader, teacher_model, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, images_annot, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        with torch.no_grad():\n",
    "            teacher_features, _, _ = teacher_model(images_annot.to(device))\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                features, _, y_preds = model(images)\n",
    "                loss = criterion(teacher_features, features, y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "        elif CFG.device == 'TPU':\n",
    "            features, _, y_preds = model(images)\n",
    "            loss = criterion(teacher_features, features, y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True) # \n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "                       lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                xm.master_print('Epoch: [{0}][{1}/{2}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                'Grad: {grad_norm:.4f}  '\n",
    "                                'LR: {lr:.6f}  '\n",
    "                                .format(\n",
    "                                epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                                grad_norm=grad_norm,\n",
    "                                lr=scheduler.get_lr()[0],\n",
    "                                ))\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025338,
     "end_time": "2021-01-31T14:22:05.182340",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.157002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.262977Z",
     "iopub.status.busy": "2021-01-31T14:22:05.247104Z",
     "iopub.status.idle": "2021-01-31T14:22:05.297053Z",
     "shell.execute_reply": "2021-01-31T14:22:05.296485Z"
    },
    "papermill": {
     "duration": 0.089364,
     "end_time": "2021-01-31T14:22:05.297189",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.207825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(fold):\n",
    "\n",
    "    if CFG.device == 'GPU':\n",
    "        LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    elif CFG.device == 'TPU':\n",
    "        if CFG.nprocs == 1:\n",
    "            LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "        elif CFG.nprocs == 8:\n",
    "            xm.master_print(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = dfx[dfx['fold'] != fold].index\n",
    "    val_idx = dfx[dfx['fold'] == fold].index\n",
    "\n",
    "    train_folds = dfx.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = dfx.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(train_folds.shape)\n",
    "    print(valid_folds.shape)\n",
    "    \n",
    "    # para anotaciones\n",
    "    if CFG.STEP == 1 or CFG.STEP == 2:\n",
    "        train_folds = train_folds[train_folds['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "        if CFG.STEP == 1:\n",
    "            valid_folds = valid_folds[valid_folds['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "        print(train_folds.shape)\n",
    "        print(valid_folds.shape)\n",
    "\n",
    "    # Para validar y asignar pesos de los modelos\n",
    "    if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "        test_fold = 0\n",
    "        train_folds = train_folds[train_folds.fold_test != test_fold].reset_index(drop=True)\n",
    "        valid_folds = valid_folds[valid_folds.fold_test != test_fold].reset_index(drop=True)\n",
    "        test_fold = dfx.loc[dfx['fold_test'] == test_fold].reset_index(drop=True)\n",
    "        print(train_folds.shape)\n",
    "        print(valid_folds.shape)\n",
    "        print(test_fold.shape)\n",
    "    \n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "\n",
    "    if CFG.STEP == 2:\n",
    "        use_annotations = True\n",
    "        transform_function_to_use_Train = get_transforms_step2(data='train')\n",
    "        transform_function_to_use_Valid = get_transforms_step2(data='valid')\n",
    "    else:\n",
    "        use_annotations = False\n",
    "        transform_function_to_use_Train = get_transforms(data='train')\n",
    "        transform_function_to_use_Valid = get_transforms(data='valid')\n",
    "        \n",
    "    train_dataset = TrainDataset(train_folds, df_annotations = train_annotations, use_annot = use_annotations,\n",
    "                                 transform = transform_function_to_use_Train)\n",
    "    valid_dataset = TrainDataset(valid_folds, df_annotations = train_annotations, use_annot = False,\n",
    "                                 transform = transform_function_to_use_Valid)\n",
    "    if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "        test_fold_dataset = TrainDataset(test_fold, df_annotations = train_annotations,\n",
    "                                     transform=get_transforms(data='valid'))\n",
    "    print('Data Loader loading ...')\n",
    "    if CFG.device == 'GPU':\n",
    "        train_loader = DataLoader(train_dataset, \n",
    "                                  batch_size=CFG.batch_size, \n",
    "                                  shuffle=True, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, \n",
    "                                  batch_size=CFG.batch_size * 2, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "            test_fold_loader = DataLoader(test_fold_dataset, \n",
    "                                      batch_size=CFG.batch_size * 2, \n",
    "                                      shuffle=False, \n",
    "                                      num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    if CFG.device == 'TPU':\n",
    "        device = xm.xla_device()\n",
    "    elif CFG.device == 'GPU':\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    print('Preparing models ...')\n",
    "    # Leemos el modelo del STEP 1 \n",
    "    if CFG.STEP == 2:\n",
    "        teacher_model = CustomResNet200D(CFG.model_name, pretrained=False)\n",
    "        teacher_model_path = CFG.teacher + \"resnet200d_320_fold\" + str(fold) + \"_step1_best_loss_cpu.pth\"\n",
    "        teacher_model.load_state_dict(torch.load(teacher_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        for param in teacher_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        teacher_model.eval()\n",
    "        teacher_model.to(device)\n",
    "        \n",
    "    # Elegimos el tipo de modelo a entrenar\n",
    "    if CFG.DO_EFFICIENT:\n",
    "        model = CustomEfficientB7(CFG.model_name, pretrained=True)\n",
    "    else:\n",
    "        model = CustomResNet200D(CFG.model_name, pretrained=True)\n",
    "        \n",
    "    # Leemos estudiante si STEP es 3\n",
    "    if CFG.STEP == 3 and CFG.CONTINUE_TRAINING == False:\n",
    "        student_model_path = CFG.student + \"resnet200d_320_fold\" + str(fold) + \"_step2_best_loss.pth\"\n",
    "        model.load_state_dict(torch.load(student_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        \n",
    "    # Continuacion de entrenamiento\n",
    "    if CFG.STEP == 3 and CFG.CONTINUE_TRAINING:\n",
    "        continue_model_path = CFG.continue_path + \"resnet200d_320_fold\" + str(fold) + \"_step3_best_loss_cpu.pth\"\n",
    "        model.load_state_dict(torch.load(continue_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "#     warmup_epo = 1 #++\n",
    "#     scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler = scheduler) #++\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    if CFG.STEP == 2:\n",
    "        train_criterion = CustomLoss(weights=CFG.weights)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "#         scheduler_warmup.step(epoch) # ++ \n",
    "        \n",
    "        # ********* train *********\n",
    "        #  ********* TPU *********\n",
    "        if CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                if CFG.STEP == 2:\n",
    "                    avg_loss = train_fn_step2(train_loader, teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "                else:\n",
    "                    avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "            elif CFG.nprocs == 8:\n",
    "                para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
    "                if CFG.STEP == 2:\n",
    "                    avg_loss = train_fn_step2(para_train_loader.per_device_loader(device), teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "                else:\n",
    "                    avg_loss = train_fn(para_train_loader.per_device_loader(device), model, criterion, optimizer, epoch, scheduler, device)\n",
    "        #  ********* GPU *********\n",
    "        elif CFG.device == 'GPU':\n",
    "            if CFG.STEP == 2:\n",
    "                avg_loss = train_fn_step2(train_loader, teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "            else:\n",
    "                avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "                \n",
    "        # ********* eval *********\n",
    "        if CFG.device == 'TPU' and CFG.nprocs == 8: # TODO test_fold\n",
    "                para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
    "                avg_val_loss, preds, valid_labels = valid_fn(para_valid_loader.per_device_loader(device), model, criterion, device)\n",
    "                preds = idist.all_gather(torch.tensor(preds)).to('cpu').numpy()\n",
    "                valid_labels = idist.all_gather(torch.tensor(valid_labels)).to('cpu').numpy()\n",
    "        else: # para TPU (1 proc) y GPU\n",
    "            avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device)\n",
    "            if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                test_fold_avg_val_loss, test_fold_preds, _ = valid_fn(test_fold_loader, model, criterion, device)\n",
    "            \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # ********* scoring *********\n",
    "        score, scores = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "            if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                LOGGER.info(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        elif CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "            elif CFG.nprocs == 8:\n",
    "                xm.master_print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                    xm.master_print(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "                xm.master_print(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        # ********************\n",
    "         # SAVE MAX SCORE\n",
    "        # ********************\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "         # ********************\n",
    "         # SAVE MIN LOSS\n",
    "        # ********************\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "    \n",
    "    if CFG.nprocs != 8:\n",
    "        check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "        for c in [f'pred_{c}' for c in CFG.target_cols]:\n",
    "            valid_folds[c] = np.nan\n",
    "        valid_folds[[f'pred_{c}' for c in CFG.target_cols]] = check_point['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.358257Z",
     "iopub.status.busy": "2021-01-31T14:22:05.356800Z",
     "iopub.status.idle": "2021-01-31T14:22:05.359531Z",
     "shell.execute_reply": "2021-01-31T14:22:05.360048Z"
    },
    "papermill": {
     "duration": 0.037049,
     "end_time": "2021-01-31T14:22:05.360197",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.323148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare: 1.train  2.folds\n",
    "    \"\"\"\n",
    "\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n",
    "        labels = result_df[CFG.target_cols].values\n",
    "        score, scores = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                if CFG.nprocs != 8:\n",
    "                    LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                    get_result(_oof_df)\n",
    "                    \n",
    "        if CFG.nprocs != 8:\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "            # save result\n",
    "            oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.418895Z",
     "iopub.status.busy": "2021-01-31T14:22:05.418292Z",
     "iopub.status.idle": "2021-01-31T20:35:29.390890Z",
     "shell.execute_reply": "2021-01-31T20:35:29.390217Z"
    },
    "papermill": {
     "duration": 22404.005227,
     "end_time": "2021-01-31T20:35:29.391072",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.385845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if CFG.device == 'TPU':\n",
    "        print('TPU MODE')\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        print('GPU MODE')\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T20:35:29.906082Z",
     "iopub.status.busy": "2021-01-31T20:35:29.905101Z",
     "iopub.status.idle": "2021-01-31T20:35:29.910066Z",
     "shell.execute_reply": "2021-01-31T20:35:29.909191Z"
    },
    "papermill": {
     "duration": 0.250079,
     "end_time": "2021-01-31T20:35:29.910257",
     "exception": false,
     "start_time": "2021-01-31T20:35:29.660178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save as cpu\n",
    "if CFG.device == 'TPU':\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            # best score\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score_cpu.pth')\n",
    "            # best loss\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss_cpu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model('resnet200d_320', pretrained=True)\n",
    "# pretrained_path = 'https://storage.cloud.google.com/extras-entrenamiento/resnet200d_ra2-bdba9bf9.pth?authuser=1'\n",
    "# model.load_state_dict(torch.load(pretrained_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22430.073624,
   "end_time": "2021-01-31T20:35:32.151605",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-31T14:21:42.077981",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04250bf656b04e39952f291e27b2951f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ba59250bba24289b441ffe234ca1da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a45f6a661f7418e9cee798ef5841f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59bf409ee678456c99320e03c9bf9108",
       "placeholder": "​",
       "style": "IPY_MODEL_3d609ddcd36448d8837bf4e0150ce61e",
       "value": "100%"
      }
     },
     "3ad2779948c24a6c92e5a61066072c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d609ddcd36448d8837bf4e0150ce61e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56923221e1b3480794c90f676cf6a5bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed5af00842624a979a085df9a77b44af",
       "placeholder": "​",
       "style": "IPY_MODEL_5e7068520e0e45b18907c3a69d80d0fa",
       "value": " 254M/254M [00:01&lt;00:00, 184MB/s]"
      }
     },
     "59bf409ee678456c99320e03c9bf9108": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a6a471c12d0479294630673baf7bffb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ba59250bba24289b441ffe234ca1da7",
       "max": 266860719,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ad2779948c24a6c92e5a61066072c04",
       "value": 266860719
      }
     },
     "5e7068520e0e45b18907c3a69d80d0fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5f22f6d28a91492298ce6d7b2c83ed38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3a45f6a661f7418e9cee798ef5841f7a",
        "IPY_MODEL_5a6a471c12d0479294630673baf7bffb",
        "IPY_MODEL_56923221e1b3480794c90f676cf6a5bb"
       ],
       "layout": "IPY_MODEL_04250bf656b04e39952f291e27b2951f"
      }
     },
     "ed5af00842624a979a085df9a77b44af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
