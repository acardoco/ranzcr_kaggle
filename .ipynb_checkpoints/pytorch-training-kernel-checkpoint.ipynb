{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022477,
     "end_time": "2021-01-31T14:21:47.713341",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.690864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.762708Z",
     "iopub.status.busy": "2021-01-31T14:21:47.761882Z",
     "iopub.status.idle": "2021-01-31T14:21:47.765190Z",
     "shell.execute_reply": "2021-01-31T14:21:47.764519Z"
    },
    "papermill": {
     "duration": 0.029226,
     "end_time": "2021-01-31T14:21:47.765360",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.736134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install -q pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.812994Z",
     "iopub.status.busy": "2021-01-31T14:21:47.812199Z",
     "iopub.status.idle": "2021-01-31T14:21:47.814853Z",
     "shell.execute_reply": "2021-01-31T14:21:47.815353Z"
    },
    "papermill": {
     "duration": 0.029416,
     "end_time": "2021-01-31T14:21:47.815561",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.786145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = 'gs://ranzcr-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021214,
     "end_time": "2021-01-31T14:21:47.857979",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.836765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.912993Z",
     "iopub.status.busy": "2021-01-31T14:21:47.912226Z",
     "iopub.status.idle": "2021-01-31T14:21:47.915050Z",
     "shell.execute_reply": "2021-01-31T14:21:47.915569Z"
    },
    "papermill": {
     "duration": 0.036682,
     "end_time": "2021-01-31T14:21:47.915747",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.879065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    device='GPU' # ['TPU', 'GPU']\n",
    "    nprocs=1 # [1, 8]\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name='resnet200d_320' # \n",
    "    size = 256#512\n",
    "    scheduler='ReduceLROnPlateau' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs = 10\n",
    "    factor=0.1 # ReduceLROnPlateau. 0.2\n",
    "    patience=0 # ReduceLROnPlateau. 4\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=5 # CosineAnnealingLR. 4\n",
    "    T_0 = 4 # CosineAnnealingWarmRestarts\n",
    "    lr= 5e-4 # 1e-4, 5e-4 para step 2\n",
    "    min_lr= 1e-6\n",
    "    batch_size= 24 # 24\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=666\n",
    "    target_size=11\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                 'Swan Ganz Catheter Present']\n",
    "    n_fold=5\n",
    "    trn_fold=[0] # [0, 1, 2, 3, 4]. \n",
    "    train=True\n",
    "    USE_TEST_FOLD = True\n",
    "    CURRENT_FOLD = 0\n",
    "    WARMUP = 10\n",
    "    STEP = 0 # 0 sin annotaciones, 1, 2 y 3\n",
    "    # step 2\n",
    "    weights=[0.5, 1]\n",
    "    teacher = '../input/resnet200d-step1-teachers/'\n",
    "    # step 3\n",
    "    student = '../input/resnet200-step2-students/'\n",
    "    # MORE LAYERS: DenseSigmoid, BatchNorm y PReLU\n",
    "    MORE_LAYERS_MODEL = False\n",
    "    student_more_layers = '../input/resnet200dstudentsstep2/'\n",
    "    # TODO para continuar entrenando\n",
    "    CONTINUE_TRAINING = False\n",
    "    continue_path = '../input/resnet200dstep3morelayersphase1/'\n",
    "    lr_continue = 5e-5 # CAMBIAR A MANO\n",
    "    # OTROS TIPOS DE MODELOS\n",
    "    DO_EFFICIENT = False\n",
    "    effnet_path = '../input/efficientnet-pytorch/'\n",
    "    # SERESNET152D\n",
    "    DO_SERESNET152D = False\n",
    "    \n",
    "# correciones\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    \n",
    "if CFG.CONTINUE_TRAINING:\n",
    "    CFG.epochs = 14\n",
    "    CFG.lr = CFG.lr_continue\n",
    "    \n",
    "if CFG.MORE_LAYERS_MODEL:\n",
    "    CFG.student = CFG.student_more_layers\n",
    "    \n",
    "if CFG.STEP == 3:\n",
    "    CFG.USE_TEST_FOLD = True\n",
    "    \n",
    "if CFG.DO_SERESNET152D:\n",
    "    CFG.model_name = 'seresnet152d_320'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:21:47.971323Z",
     "iopub.status.busy": "2021-01-31T14:21:47.970633Z",
     "iopub.status.idle": "2021-01-31T14:22:00.450231Z",
     "shell.execute_reply": "2021-01-31T14:22:00.448595Z"
    },
    "papermill": {
     "duration": 12.512386,
     "end_time": "2021-01-31T14:22:00.450394",
     "exception": false,
     "start_time": "2021-01-31T14:21:47.938008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.0.tar.gz (20 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.7.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-py3-none-any.whl size=16033 sha256=3eb817a52468eb038d30d5b8ce99717207e958bc9a7c19890018cd90ab48c5cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/cc/0d/41d384b0071c6f46e542aded5f8571700ace4f1eb3f1591c29\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    os.system('curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py')\n",
    "    os.system('python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev')\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.batch_size = CFG.batch_size // CFG.nprocs\n",
    "    \n",
    "if CFG.DO_EFFICIENT:\n",
    "    !pip install efficientnet_pytorch\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    CFG.lr = 3e-3\n",
    "    CFG.model_name = \"efficientnet-b7\"\n",
    "    #CFG.size= 600\n",
    "    CFG.epochs = 10 \n",
    "    if CFG.device == 'GPU':\n",
    "        CFG.batch_size = 8\n",
    "    if CFG.device == 'TPU':\n",
    "        CFG.batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026861,
     "end_time": "2021-01-31T14:22:00.506625",
     "exception": false,
     "start_time": "2021-01-31T14:22:00.479764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:00.574792Z",
     "iopub.status.busy": "2021-01-31T14:22:00.573923Z",
     "iopub.status.idle": "2021-01-31T14:22:03.844914Z",
     "shell.execute_reply": "2021-01-31T14:22:03.843741Z"
    },
    "papermill": {
     "duration": 3.311409,
     "end_time": "2021-01-31T14:22:03.845102",
     "exception": false,
     "start_time": "2021-01-31T14:22:00.533693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('gs://extras-entrenamiento/pytorch_image_models')\n",
    "# sys.path.append('gs://extras-entrenamiento/input/pytorch-images-seresnet')\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "# from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "import albumentations\n",
    "from albumentations import *\n",
    "\n",
    "import timm\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026475,
     "end_time": "2021-01-31T14:22:03.899542",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.873067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:03.961251Z",
     "iopub.status.busy": "2021-01-31T14:22:03.960310Z",
     "iopub.status.idle": "2021-01-31T14:22:03.970184Z",
     "shell.execute_reply": "2021-01-31T14:22:03.969624Z"
    },
    "papermill": {
     "duration": 0.04609,
     "end_time": "2021-01-31T14:22:03.970312",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.924222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025661,
     "end_time": "2021-01-31T14:22:04.021054",
     "exception": false,
     "start_time": "2021-01-31T14:22:03.995393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.077687Z",
     "iopub.status.busy": "2021-01-31T14:22:04.077061Z",
     "iopub.status.idle": "2021-01-31T14:22:04.378228Z",
     "shell.execute_reply": "2021-01-31T14:22:04.378845Z"
    },
    "papermill": {
     "duration": 0.332513,
     "end_time": "2021-01-31T14:22:04.379053",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.046540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds are:  [0, 1, 2, 3, 4]\n",
      "Selected folds are:  [0]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\n",
    "dfx = pd.read_csv('../input/split-k-folds/train_folds.csv')\n",
    "train_annotations = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train_annotations.csv')\n",
    "\n",
    "print(\"Folds are: \", sorted(dfx.fold.unique()))\n",
    "print(\"Selected folds are: \", CFG.trn_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024139,
     "end_time": "2021-01-31T14:22:04.428196",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.404057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.503284Z",
     "iopub.status.busy": "2021-01-31T14:22:04.501667Z",
     "iopub.status.idle": "2021-01-31T14:22:04.504490Z",
     "shell.execute_reply": "2021-01-31T14:22:04.505012Z"
    },
    "papermill": {
     "duration": 0.049967,
     "end_time": "2021-01-31T14:22:04.505157",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.455190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "COLOR_MAP = {'ETT - Abnormal': (255, 0, 0),\n",
    "             'ETT - Borderline': (0, 255, 0),\n",
    "             'ETT - Normal': (0, 0, 255),\n",
    "             'NGT - Abnormal': (255, 255, 0),\n",
    "             'NGT - Borderline': (255, 0, 255),\n",
    "             'NGT - Incompletely Imaged': (0, 255, 255),\n",
    "             'NGT - Normal': (128, 0, 0),\n",
    "             'CVC - Abnormal': (0, 128, 0),\n",
    "             'CVC - Borderline': (0, 0, 128),\n",
    "             'CVC - Normal': (128, 128, 0),\n",
    "             'Swan Ganz Catheter Present': (128, 0, 128),\n",
    "            }\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, df_annotations, annot_size=50, transform=None, use_annot=False):\n",
    "        self.df = df\n",
    "        self.df_annotations = df_annotations\n",
    "        self.use_annot = use_annot\n",
    "        self.annot_size = annot_size\n",
    "        self.file_names = df['StudyInstanceUID'].values\n",
    "        self.labels = df[CFG.target_cols].values\n",
    "        self.transform = transform\n",
    "        self.shape = df.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TRAIN_PATH}/{file_name}.jpg'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = torch.tensor(self.labels[idx]).float()\n",
    "        # annotated imageç\n",
    "        # STEP 1 o 2\n",
    "        if CFG.STEP > 0 and CFG.STEP < 3:\n",
    "            #STEP 2\n",
    "            if CFG.STEP == 2 and self.use_annot:\n",
    "                image_annot = image.copy()\n",
    "            query_string = f\"StudyInstanceUID == '{file_name}'\"\n",
    "            df = self.df_annotations.query(query_string)\n",
    "            for i, row in df.iterrows():\n",
    "                label = row[\"label\"]\n",
    "                data = np.array(ast.literal_eval(row[\"data\"]))\n",
    "                for d in data:\n",
    "                    # STEP 2\n",
    "                    if CFG.STEP == 2 and self.use_annot:\n",
    "                        image_annot[d[1]-self.annot_size//2:d[1]+self.annot_size//2,\n",
    "                                d[0]-self.annot_size//2:d[0]+self.annot_size//2,\n",
    "                                :] = COLOR_MAP[label]\n",
    "                    # STEP 1\n",
    "                    else:\n",
    "                        image[d[1]-self.annot_size//2:d[1]+self.annot_size//2,\n",
    "                              d[0]-self.annot_size//2:d[0]+self.annot_size//2,\n",
    "                              :] = COLOR_MAP[label]\n",
    "        # aplicar transform\n",
    "        if CFG.STEP == 2 and self.use_annot:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, image_annot=image_annot)\n",
    "                image = augmented['image']\n",
    "                image_annot = augmented['image_annot']\n",
    "            return image, image_annot, labels\n",
    "        else:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "            return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025151,
     "end_time": "2021-01-31T14:22:04.555809",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.530658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.626582Z",
     "iopub.status.busy": "2021-01-31T14:22:04.619316Z",
     "iopub.status.idle": "2021-01-31T14:22:04.629187Z",
     "shell.execute_reply": "2021-01-31T14:22:04.628729Z"
    },
    "papermill": {
     "duration": 0.048509,
     "end_time": "2021-01-31T14:22:04.629307",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.580798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "# def get_transforms(*, data):\n",
    "    \n",
    "#     if data == 'train':\n",
    "#         return Compose([\n",
    "#            albumentations.RandomResizedCrop(CFG.size, CFG.size, scale=(0.9, 1), p=1), \n",
    "#            albumentations.HorizontalFlip(p=0.5),\n",
    "#            albumentations.ShiftScaleRotate(p=0.5),\n",
    "#            albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n",
    "#            albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n",
    "#            albumentations.CLAHE(clip_limit=(1,4), p=0.5),\n",
    "#            albumentations.OneOf([\n",
    "#                albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "#                albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "#                albumentations.ElasticTransform(alpha=3),\n",
    "#            ], p=0.2),\n",
    "#            albumentations.OneOf([\n",
    "#                albumentations.GaussNoise(var_limit=[10, 50]),\n",
    "#                albumentations.GaussianBlur(),\n",
    "#                albumentations.MotionBlur(),\n",
    "#                albumentations.MedianBlur(),\n",
    "#            ], p=0.2),\n",
    "#           albumentations.Resize(CFG.size, CFG.size),\n",
    "#           albumentations.OneOf([\n",
    "#               JpegCompression(),\n",
    "#               Downscale(scale_min=0.1, scale_max=0.15),\n",
    "#           ], p=0.2),\n",
    "#           IAAPiecewiseAffine(p=0.2),\n",
    "#           IAASharpen(p=0.2),\n",
    "#           albumentations.Cutout(max_h_size=int(CFG.size * 0.1), max_w_size=int(CFG.size * 0.1), num_holes=5, p=0.5),\n",
    "#           albumentations.Normalize(),\n",
    "#         ToTensorV2(),\n",
    "#         ])\n",
    "\n",
    "#     elif data == 'valid':\n",
    "#         return Compose([\n",
    "#             albumentations.Resize(CFG.size, CFG.size),\n",
    "#            albumentations.Normalize(),\n",
    "#         ToTensorV2(),\n",
    "#         ])\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "def get_transforms_step2(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ], additional_targets={'image_annot': 'image'})\n",
    "    \n",
    "    elif data == 'check':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            #Normalize(\n",
    "            #    mean=[0.485, 0.456, 0.406],\n",
    "            #    std=[0.229, 0.224, 0.225],\n",
    "            #),\n",
    "            ToTensorV2(),\n",
    "        ], additional_targets={'image_annot': 'image'})\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.684244Z",
     "iopub.status.busy": "2021-01-31T14:22:04.683663Z",
     "iopub.status.idle": "2021-01-31T14:22:04.687899Z",
     "shell.execute_reply": "2021-01-31T14:22:04.687443Z"
    },
    "papermill": {
     "duration": 0.033824,
     "end_time": "2021-01-31T14:22:04.688024",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.654200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# # annotated\n",
    "# if CFG.STEP == 1:\n",
    "#     train_dataset = TrainDataset(dfx[dfx['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True),\n",
    "#                              df_annotations = train_annotations, transform = None)\n",
    "# elif CFG.STEP == 2:\n",
    "#     train_dataset = TrainDataset(dfx[dfx['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True),\n",
    "#                              df_annotations = train_annotations, transform=get_transforms_step2(data='check'), use_annot=True)\n",
    "# else:\n",
    "#     train_dataset = TrainDataset(dfx, df_annotations = train_annotations, transform=None)\n",
    "    \n",
    "# print(train_dataset.shape)\n",
    "\n",
    "# for i in range(5):\n",
    "#     if CFG.STEP == 2:\n",
    "#         image, image_annot, label = train_dataset[i]\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(image.transpose(0, 1).transpose(1, 2))\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(image_annot.transpose(0, 1).transpose(1, 2))\n",
    "#         plt.title(f'label: {label}')\n",
    "#         plt.show() \n",
    "#     else:\n",
    "#         image, label = train_dataset[i]\n",
    "#         plt.imshow(image)\n",
    "#         plt.title(f'label: {label}')\n",
    "#         plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024985,
     "end_time": "2021-01-31T14:22:04.738007",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.713022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.807210Z",
     "iopub.status.busy": "2021-01-31T14:22:04.805309Z",
     "iopub.status.idle": "2021-01-31T14:22:04.808023Z",
     "shell.execute_reply": "2021-01-31T14:22:04.808585Z"
    },
    "papermill": {
     "duration": 0.045842,
     "end_time": "2021-01-31T14:22:04.808756",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.762914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL RESNET 200D\n",
    "# ====================================================\n",
    "class CustomResNet200D(nn.Module):\n",
    "    def __init__(self, model_name='resnet200d_320', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        if pretrained:\n",
    "            pretrained_path = '../input/resnet200d-pretrained-weight/resnet200d_ra2-bdba9bf9.pth'\n",
    "            self.model.load_state_dict(torch.load(pretrained_path))\n",
    "            print(f'load {model_name} pretrained model')\n",
    "        n_features = self.model.fc.in_features # son 2048\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            self.sigmoid_fc = nn.Linear(in_features=n_features, out_features=512)\n",
    "            self.bs = nn.BatchNorm1d(num_features = 512)\n",
    "            self.prelu = nn.PReLU()\n",
    "            self.fc = nn.Linear(512, CFG.target_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            output = F.sigmoid(self.sigmoid_fc(pooled_features))\n",
    "            output = self.bs(output)\n",
    "            output = self.prelu(output)\n",
    "            output = self.fc(output) #output pooled_features\n",
    "        else:\n",
    "            output = self.fc(pooled_features)\n",
    "        # features, _, y_preds\n",
    "        return features, pooled_features, output\n",
    "    \n",
    "    \n",
    "# ====================================================\n",
    "# MODEL EFFICIENT B7\n",
    "# ====================================================\n",
    "class CustomEfficientB7(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet-b7', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.effnet = EfficientNet.from_pretrained(model_name) \n",
    "        n_features = self.effnet._fc.in_features\n",
    "#         self.effnet._conv_stem.in_channels = 1\n",
    "#         weight = self.effnet._conv_stem.weight.mean(1, keepdim=True)\n",
    "#         self.effnet._conv_stem.weight = torch.nn.Parameter(weight)\n",
    "        self.effnet._fc = nn.Identity()\n",
    "        \n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            self.sigmoid_fc = nn.Linear(in_features=n_features, out_features=512)\n",
    "            self.bs = nn.BatchNorm1d(num_features = 512)\n",
    "            self.prelu = nn.PReLU()\n",
    "            self.out = nn.Linear(512, CFG.target_size)\n",
    "        else:\n",
    "            self.out = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size = image.size(0)\n",
    "    \n",
    "        x = self.effnet.extract_features(image)\n",
    "        pooled_features = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        if CFG.MORE_LAYERS_MODEL:\n",
    "            output = F.sigmoid(self.sigmoid_fc(pooled_features))\n",
    "            output = self.bs(output)\n",
    "            output = self.prelu(output)\n",
    "            output = self.out(output)\n",
    "        else:\n",
    "            output = self.out(pooled_features)\n",
    "        # features, _, y_preds\n",
    "        return x, pooled_features, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024307,
     "end_time": "2021-01-31T14:22:04.857819",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.833512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Funcion Loss para step 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:04.914593Z",
     "iopub.status.busy": "2021-01-31T14:22:04.912893Z",
     "iopub.status.idle": "2021-01-31T14:22:04.915248Z",
     "shell.execute_reply": "2021-01-31T14:22:04.915725Z"
    },
    "papermill": {
     "duration": 0.033285,
     "end_time": "2021-01-31T14:22:04.915859",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.882574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1]):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "        \n",
    "    def forward(self, teacher_features, features, y_pred, labels):\n",
    "        consistency_loss = nn.MSELoss()(teacher_features.view(-1), features.view(-1))\n",
    "        cls_loss = nn.BCEWithLogitsLoss()(y_pred, labels)\n",
    "        loss = self.weights[0] * consistency_loss + self.weights[1] * cls_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025491,
     "end_time": "2021-01-31T14:22:04.966985",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.941494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.042740Z",
     "iopub.status.busy": "2021-01-31T14:22:05.027020Z",
     "iopub.status.idle": "2021-01-31T14:22:05.056340Z",
     "shell.execute_reply": "2021-01-31T14:22:05.055837Z"
    },
    "papermill": {
     "duration": 0.063807,
     "end_time": "2021-01-31T14:22:05.056495",
     "exception": false,
     "start_time": "2021-01-31T14:22:04.992688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "# https://www.kaggle.com/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n",
    "# class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "#     def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "#         super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "#     def get_lr(self):\n",
    "#         if self.last_epoch > self.total_epoch:\n",
    "#             if self.after_scheduler:\n",
    "#                 if not self.finished:\n",
    "#                     self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "#                     self.finished = True\n",
    "#                 return self.after_scheduler.get_lr()\n",
    "#             return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "#         if self.multiplier == 1.0:\n",
    "#             return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "#         else:\n",
    "#             return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                _, _, y_preds = model(images)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "        elif CFG.device == 'TPU':\n",
    "            _, _, y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "#                       'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "#                        lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                xm.master_print('Epoch: [{0}][{1}/{2}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                'Grad: {grad_norm:.4f}  '\n",
    "#                                 'LR: {lr:.6f}  '\n",
    "                                .format(\n",
    "                                epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                                grad_norm=grad_norm,\n",
    "#                                 lr=scheduler.get_lr()[0],\n",
    "                                ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            _, _, y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      .format(\n",
    "                       step, len(valid_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                xm.master_print('EVAL: [{0}/{1}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                .format(\n",
    "                                step, len(valid_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                                ))\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.129144Z",
     "iopub.status.busy": "2021-01-31T14:22:05.121767Z",
     "iopub.status.idle": "2021-01-31T14:22:05.131690Z",
     "shell.execute_reply": "2021-01-31T14:22:05.131173Z"
    },
    "papermill": {
     "duration": 0.049606,
     "end_time": "2021-01-31T14:22:05.131816",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.082210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************************************************************\n",
    "# **************************************** FOR STEP 2 ************************************************\n",
    "# ****************************************************************************************************\n",
    "def train_fn_step2(train_loader, teacher_model, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, images_annot, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        with torch.no_grad():\n",
    "            teacher_features, _, _ = teacher_model(images_annot.to(device))\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                features, _, y_preds = model(images)\n",
    "                loss = criterion(teacher_features, features, y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "        elif CFG.device == 'TPU':\n",
    "            features, _, y_preds = model(images)\n",
    "            loss = criterion(teacher_features, features, y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True) # \n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "                       lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                xm.master_print('Epoch: [{0}][{1}/{2}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                'Grad: {grad_norm:.4f}  '\n",
    "                                'LR: {lr:.6f}  '\n",
    "                                .format(\n",
    "                                epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                                grad_norm=grad_norm,\n",
    "                                lr=scheduler.get_lr()[0],\n",
    "                                ))\n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025338,
     "end_time": "2021-01-31T14:22:05.182340",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.157002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.262977Z",
     "iopub.status.busy": "2021-01-31T14:22:05.247104Z",
     "iopub.status.idle": "2021-01-31T14:22:05.297053Z",
     "shell.execute_reply": "2021-01-31T14:22:05.296485Z"
    },
    "papermill": {
     "duration": 0.089364,
     "end_time": "2021-01-31T14:22:05.297189",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.207825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(fold):\n",
    "\n",
    "    if CFG.device == 'GPU':\n",
    "        LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    elif CFG.device == 'TPU':\n",
    "        if CFG.nprocs == 1:\n",
    "            LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "        elif CFG.nprocs == 8:\n",
    "            xm.master_print(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = dfx[dfx['fold'] != fold].index\n",
    "    val_idx = dfx[dfx['fold'] == fold].index\n",
    "\n",
    "    train_folds = dfx.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = dfx.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(train_folds.shape)\n",
    "    print(valid_folds.shape)\n",
    "    \n",
    "    # para anotaciones\n",
    "    if CFG.STEP == 1 or CFG.STEP == 2:\n",
    "        train_folds = train_folds[train_folds['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "        if CFG.STEP == 1:\n",
    "            valid_folds = valid_folds[valid_folds['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "        print(train_folds.shape)\n",
    "        print(valid_folds.shape)\n",
    "\n",
    "    # Para validar y asignar pesos de los modelos\n",
    "    if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "        test_fold = 0\n",
    "        train_folds = train_folds[train_folds.fold_test != test_fold].reset_index(drop=True)\n",
    "        valid_folds = valid_folds[valid_folds.fold_test != test_fold].reset_index(drop=True)\n",
    "        test_fold = dfx.loc[dfx['fold_test'] == test_fold].reset_index(drop=True)\n",
    "        print(train_folds.shape)\n",
    "        print(valid_folds.shape)\n",
    "        print(test_fold.shape)\n",
    "    \n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "\n",
    "    if CFG.STEP == 2:\n",
    "        use_annotations = True\n",
    "        transform_function_to_use_Train = get_transforms_step2(data='train')\n",
    "        transform_function_to_use_Valid = get_transforms_step2(data='valid')\n",
    "    else:\n",
    "        use_annotations = False\n",
    "        transform_function_to_use_Train = get_transforms(data='train')\n",
    "        transform_function_to_use_Valid = get_transforms(data='valid')\n",
    "        \n",
    "    train_dataset = TrainDataset(train_folds, df_annotations = train_annotations, use_annot = use_annotations,\n",
    "                                 transform = transform_function_to_use_Train)\n",
    "    valid_dataset = TrainDataset(valid_folds, df_annotations = train_annotations, use_annot = False,\n",
    "                                 transform = transform_function_to_use_Valid)\n",
    "    if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "        test_fold_dataset = TrainDataset(test_fold, df_annotations = train_annotations,\n",
    "                                     transform=get_transforms(data='valid'))\n",
    "\n",
    "    if CFG.device == 'GPU':\n",
    "        train_loader = DataLoader(train_dataset, \n",
    "                                  batch_size=CFG.batch_size, \n",
    "                                  shuffle=True, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, \n",
    "                                  batch_size=CFG.batch_size * 2, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "            test_fold_loader = DataLoader(test_fold_dataset, \n",
    "                                      batch_size=CFG.batch_size * 2, \n",
    "                                      shuffle=False, \n",
    "                                      num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                        num_replicas=xm.xrt_world_size(),\n",
    "                                                                        rank=xm.get_ordinal(),\n",
    "                                                                        shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=CFG.batch_size,\n",
    "                                                   sampler=train_sampler,\n",
    "                                                   drop_last=True,\n",
    "                                                   num_workers=CFG.num_workers)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset,\n",
    "                                                                        num_replicas=xm.xrt_world_size(),\n",
    "                                                                        rank=xm.get_ordinal(),\n",
    "                                                                        shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                   batch_size=CFG.batch_size * 2,\n",
    "                                                   sampler=valid_sampler,\n",
    "                                                   drop_last=False,\n",
    "                                                   num_workers=CFG.num_workers)\n",
    "        if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "            test_fold_sampler = torch.utils.data.distributed.DistributedSampler(test_fold_dataset,\n",
    "                                                                            num_replicas=xm.xrt_world_size(),\n",
    "                                                                            rank=xm.get_ordinal(),\n",
    "                                                                            shuffle=False)\n",
    "            test_fold_loader = torch.utils.data.DataLoader(test_fold_dataset,\n",
    "                                                       batch_size=CFG.batch_size * 2,\n",
    "                                                       sampler=test_fold_sampler,\n",
    "                                                       drop_last=False,\n",
    "                                                       num_workers=CFG.num_workers)\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    if CFG.device == 'TPU':\n",
    "        device = xm.xla_device()\n",
    "    elif CFG.device == 'GPU':\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "       \n",
    "    # Leemos el modelo del STEP 1 \n",
    "    if CFG.STEP == 2:\n",
    "        teacher_model = CustomResNet200D(CFG.model_name, pretrained=False)\n",
    "        teacher_model_path = CFG.teacher + \"resnet200d_320_fold\" + str(fold) + \"_step1_best_loss_cpu.pth\"\n",
    "        teacher_model.load_state_dict(torch.load(teacher_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        for param in teacher_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        teacher_model.eval()\n",
    "        teacher_model.to(device)\n",
    "        \n",
    "    # Elegimos el tipo de modelo a entrenar\n",
    "    if CFG.DO_EFFICIENT:\n",
    "        model = CustomEfficientB7(CFG.model_name, pretrained=True)\n",
    "    else:\n",
    "        model = CustomResNet200D(CFG.model_name, pretrained=True)\n",
    "        \n",
    "    # Leemos estudiante si STEP es 3\n",
    "    if CFG.STEP == 3 and CFG.CONTINUE_TRAINING == False:\n",
    "        student_model_path = CFG.student + \"resnet200d_320_fold\" + str(fold) + \"_step2_best_loss.pth\"\n",
    "        model.load_state_dict(torch.load(student_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        \n",
    "    # Continuacion de entrenamiento\n",
    "    if CFG.STEP == 3 and CFG.CONTINUE_TRAINING:\n",
    "        continue_model_path = CFG.continue_path + \"resnet200d_320_fold\" + str(fold) + \"_step3_best_loss_cpu.pth\"\n",
    "        model.load_state_dict(torch.load(continue_model_path, map_location=torch.device('cpu'))['model'])\n",
    "        \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "#     warmup_epo = 1 #++\n",
    "#     scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler = scheduler) #++\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    if CFG.STEP == 2:\n",
    "        train_criterion = CustomLoss(weights=CFG.weights)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "#         scheduler_warmup.step(epoch) # ++ \n",
    "        \n",
    "        # ********* train *********\n",
    "        #  ********* TPU *********\n",
    "        if CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                if CFG.STEP == 2:\n",
    "                    avg_loss = train_fn_step2(train_loader, teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "                else:\n",
    "                    avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "            elif CFG.nprocs == 8:\n",
    "                para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
    "                if CFG.STEP == 2:\n",
    "                    avg_loss = train_fn_step2(para_train_loader.per_device_loader(device), teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "                else:\n",
    "                    avg_loss = train_fn(para_train_loader.per_device_loader(device), model, criterion, optimizer, epoch, scheduler, device)\n",
    "        #  ********* GPU *********\n",
    "        elif CFG.device == 'GPU':\n",
    "            if CFG.STEP == 2:\n",
    "                avg_loss = train_fn_step2(train_loader, teacher_model, model, train_criterion, optimizer, epoch, scheduler, device)\n",
    "            else:\n",
    "                avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "                \n",
    "        # ********* eval *********\n",
    "        if CFG.device == 'TPU' and CFG.nprocs == 8: # TODO test_fold\n",
    "                para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
    "                avg_val_loss, preds, valid_labels = valid_fn(para_valid_loader.per_device_loader(device), model, criterion, device)\n",
    "                preds = idist.all_gather(torch.tensor(preds)).to('cpu').numpy()\n",
    "                valid_labels = idist.all_gather(torch.tensor(valid_labels)).to('cpu').numpy()\n",
    "        else: # para TPU (1 proc) y GPU\n",
    "            avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device)\n",
    "            if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                test_fold_avg_val_loss, test_fold_preds, _ = valid_fn(test_fold_loader, model, criterion, device)\n",
    "            \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # ********* scoring *********\n",
    "        score, scores = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "            if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                LOGGER.info(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        elif CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "            elif CFG.nprocs == 8:\n",
    "                xm.master_print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                if CFG.USE_TEST_FOLD and (CFG.STEP == 0 or CFG.STEP == 3):\n",
    "                    xm.master_print(f'Epoch {epoch+1} - test_fold_avg_val_loss: {test_fold_avg_val_loss:.4f}')\n",
    "                xm.master_print(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        # ********************\n",
    "         # SAVE MAX SCORE\n",
    "        # ********************\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "         # ********************\n",
    "         # SAVE MIN LOSS\n",
    "        # ********************\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "    \n",
    "    if CFG.nprocs != 8:\n",
    "        check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "        for c in [f'pred_{c}' for c in CFG.target_cols]:\n",
    "            valid_folds[c] = np.nan\n",
    "        valid_folds[[f'pred_{c}' for c in CFG.target_cols]] = check_point['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.358257Z",
     "iopub.status.busy": "2021-01-31T14:22:05.356800Z",
     "iopub.status.idle": "2021-01-31T14:22:05.359531Z",
     "shell.execute_reply": "2021-01-31T14:22:05.360048Z"
    },
    "papermill": {
     "duration": 0.037049,
     "end_time": "2021-01-31T14:22:05.360197",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.323148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare: 1.train  2.folds\n",
    "    \"\"\"\n",
    "\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n",
    "        labels = result_df[CFG.target_cols].values\n",
    "        score, scores = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                if CFG.nprocs != 8:\n",
    "                    LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                    get_result(_oof_df)\n",
    "                    \n",
    "        if CFG.nprocs != 8:\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "            # save result\n",
    "            oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-31T14:22:05.418895Z",
     "iopub.status.busy": "2021-01-31T14:22:05.418292Z",
     "iopub.status.idle": "2021-01-31T20:35:29.390890Z",
     "shell.execute_reply": "2021-01-31T20:35:29.390217Z"
    },
    "papermill": {
     "duration": 22404.005227,
     "end_time": "2021-01-31T20:35:29.391072",
     "exception": false,
     "start_time": "2021-01-31T14:22:05.385845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU MODE\n",
      "(24080, 15)\n",
      "(6003, 15)\n",
      "(23091, 15)\n",
      "(5747, 15)\n",
      "(1245, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f22f6d28a91492298ce6d7b2c83ed38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Epoch: [1][0/2886] Data 2.107 (2.107) Elapsed 0m 4s (remain 204m 41s) Loss: 0.7025(0.7025) Grad: inf  \n",
      "Epoch: [1][100/2886] Data 0.000 (0.021) Elapsed 1m 11s (remain 32m 49s) Loss: 0.3079(0.3713) Grad: 4630.0894  \n",
      "Epoch: [1][200/2886] Data 0.000 (0.011) Elapsed 2m 18s (remain 30m 46s) Loss: 0.3493(0.3575) Grad: 1765.6630  \n",
      "Epoch: [1][300/2886] Data 0.000 (0.007) Elapsed 3m 24s (remain 29m 18s) Loss: 0.2624(0.3449) Grad: 605.0746  \n",
      "Epoch: [1][400/2886] Data 0.000 (0.005) Elapsed 4m 31s (remain 28m 0s) Loss: 0.3914(0.3378) Grad: 3030.8811  \n",
      "Epoch: [1][500/2886] Data 0.000 (0.004) Elapsed 5m 36s (remain 26m 40s) Loss: 0.2335(0.3326) Grad: 464.9859  \n",
      "Epoch: [1][600/2886] Data 0.000 (0.004) Elapsed 6m 44s (remain 25m 37s) Loss: 0.3564(0.3261) Grad: 1377.2668  \n",
      "Epoch: [1][700/2886] Data 0.000 (0.003) Elapsed 7m 50s (remain 24m 27s) Loss: 0.3464(0.3222) Grad: 450.5427  \n",
      "Epoch: [1][800/2886] Data 0.000 (0.003) Elapsed 8m 55s (remain 23m 13s) Loss: 0.3303(0.3200) Grad: 204.3639  \n",
      "Epoch: [1][900/2886] Data 0.000 (0.003) Elapsed 10m 1s (remain 22m 5s) Loss: 0.2220(0.3188) Grad: 610.5019  \n",
      "Epoch: [1][1000/2886] Data 0.000 (0.002) Elapsed 11m 7s (remain 20m 57s) Loss: 0.2992(0.3181) Grad: 292.5182  \n",
      "Epoch: [1][1100/2886] Data 0.000 (0.002) Elapsed 12m 11s (remain 19m 45s) Loss: 0.3411(0.3165) Grad: 199.5403  \n",
      "Epoch: [1][1200/2886] Data 0.000 (0.002) Elapsed 13m 14s (remain 18m 35s) Loss: 0.2397(0.3154) Grad: 102.4593  \n",
      "Epoch: [1][1300/2886] Data 0.000 (0.002) Elapsed 14m 17s (remain 17m 24s) Loss: 0.4349(0.3146) Grad: 126.5745  \n",
      "Epoch: [1][1400/2886] Data 0.000 (0.002) Elapsed 15m 19s (remain 16m 14s) Loss: 0.3265(0.3132) Grad: 93.5370  \n",
      "Epoch: [1][1500/2886] Data 0.000 (0.002) Elapsed 16m 21s (remain 15m 5s) Loss: 0.3679(0.3119) Grad: 173.3025  \n",
      "Epoch: [1][1600/2886] Data 0.000 (0.002) Elapsed 17m 22s (remain 13m 57s) Loss: 0.1716(0.3115) Grad: 87.3571  \n",
      "Epoch: [1][1700/2886] Data 0.000 (0.001) Elapsed 18m 23s (remain 12m 48s) Loss: 0.2967(0.3108) Grad: 192.7120  \n",
      "Epoch: [1][1800/2886] Data 0.000 (0.001) Elapsed 19m 24s (remain 11m 41s) Loss: 0.2614(0.3108) Grad: 87.3605  \n",
      "Epoch: [1][1900/2886] Data 0.000 (0.001) Elapsed 20m 24s (remain 10m 34s) Loss: 0.2407(0.3101) Grad: 92.6887  \n",
      "Epoch: [1][2000/2886] Data 0.000 (0.001) Elapsed 21m 25s (remain 9m 28s) Loss: 0.2885(0.3092) Grad: 65.9450  \n",
      "Epoch: [1][2100/2886] Data 0.000 (0.001) Elapsed 22m 26s (remain 8m 23s) Loss: 0.2400(0.3090) Grad: 143.7209  \n",
      "Epoch: [1][2200/2886] Data 0.000 (0.001) Elapsed 23m 27s (remain 7m 17s) Loss: 0.2403(0.3087) Grad: 54.2536  \n",
      "Epoch: [1][2300/2886] Data 0.000 (0.001) Elapsed 24m 27s (remain 6m 13s) Loss: 0.2047(0.3085) Grad: 56.5519  \n",
      "Epoch: [1][2400/2886] Data 0.000 (0.001) Elapsed 25m 28s (remain 5m 8s) Loss: 0.3319(0.3089) Grad: 72.0170  \n",
      "Epoch: [1][2500/2886] Data 0.000 (0.001) Elapsed 26m 28s (remain 4m 4s) Loss: 0.3287(0.3084) Grad: 44.8569  \n",
      "Epoch: [1][2600/2886] Data 0.000 (0.001) Elapsed 27m 28s (remain 3m 0s) Loss: 0.3002(0.3083) Grad: 41.1853  \n",
      "Epoch: [1][2700/2886] Data 0.000 (0.001) Elapsed 28m 28s (remain 1m 57s) Loss: 0.2255(0.3081) Grad: 46.2170  \n",
      "Epoch: [1][2800/2886] Data 0.000 (0.001) Elapsed 29m 27s (remain 0m 53s) Loss: 0.1956(0.3078) Grad: 58.3704  \n",
      "Epoch: [1][2885/2886] Data 0.000 (0.001) Elapsed 30m 18s (remain 0m 0s) Loss: 0.2785(0.3076) Grad: 111.0576  \n",
      "EVAL: [0/360] Data 2.717 (2.717) Elapsed 0m 2s (remain 17m 46s) Loss: 0.2601(0.2601) \n",
      "EVAL: [100/360] Data 1.881 (0.521) Elapsed 1m 11s (remain 3m 4s) Loss: 0.3420(0.6194) \n",
      "EVAL: [200/360] Data 0.000 (0.494) Elapsed 2m 18s (remain 1m 49s) Loss: 1.6918(0.6489) \n",
      "EVAL: [300/360] Data 0.000 (0.488) Elapsed 3m 26s (remain 0m 40s) Loss: 1.2453(0.7028) \n",
      "EVAL: [359/360] Data 0.000 (0.484) Elapsed 4m 5s (remain 0m 0s) Loss: 0.2245(0.6948) \n",
      "EVAL: [0/78] Data 2.503 (2.503) Elapsed 0m 2s (remain 3m 30s) Loss: 0.2665(0.2665) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.3076  avg_val_loss: 0.6948  time: 2119s\n",
      "Epoch 1 - test_fold_avg_val_loss: 0.7753\n",
      "Epoch 1 - Score: 0.5120  Scores: [0.6151 0.4979 0.5559 0.4281 0.4724 0.5113 0.5586 0.5294 0.4914 0.5087\n",
      " 0.4635]\n",
      "Epoch 1 - Save Best Score: 0.5120 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.000 (0.515) Elapsed 0m 55s (remain 0m 0s) Loss: 0.3854(0.7753) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Save Best Loss: 0.6948 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/2886] Data 1.195 (1.195) Elapsed 0m 2s (remain 107m 6s) Loss: 0.2366(0.2366) Grad: nan  \n",
      "Epoch: [2][100/2886] Data 0.000 (0.012) Elapsed 1m 4s (remain 29m 51s) Loss: 0.2212(0.2925) Grad: 1614.6404  \n",
      "Epoch: [2][200/2886] Data 0.000 (0.006) Elapsed 2m 5s (remain 28m 1s) Loss: 0.3181(0.2949) Grad: 1596.9803  \n",
      "Epoch: [2][300/2886] Data 0.000 (0.004) Elapsed 3m 6s (remain 26m 44s) Loss: 0.2874(0.2951) Grad: 1646.7621  \n",
      "Epoch: [2][400/2886] Data 0.000 (0.003) Elapsed 4m 7s (remain 25m 36s) Loss: 0.2039(0.2988) Grad: 1809.1692  \n",
      "Epoch: [2][500/2886] Data 0.000 (0.003) Elapsed 5m 9s (remain 24m 33s) Loss: 0.2830(0.2993) Grad: 4674.8286  \n",
      "Epoch: [2][600/2886] Data 0.000 (0.002) Elapsed 6m 11s (remain 23m 33s) Loss: 0.3408(0.2985) Grad: 1923.9854  \n",
      "Epoch: [2][700/2886] Data 0.000 (0.002) Elapsed 7m 13s (remain 22m 32s) Loss: 0.3429(0.2972) Grad: 1899.5752  \n",
      "Epoch: [2][800/2886] Data 0.000 (0.002) Elapsed 8m 15s (remain 21m 30s) Loss: 0.2831(0.2958) Grad: 1673.6250  \n",
      "Epoch: [2][900/2886] Data 0.000 (0.002) Elapsed 9m 18s (remain 20m 30s) Loss: 0.3199(0.2964) Grad: 1321.7488  \n",
      "Epoch: [2][1000/2886] Data 0.000 (0.001) Elapsed 10m 19s (remain 19m 27s) Loss: 0.3792(0.2984) Grad: 1768.4291  \n",
      "Epoch: [2][1100/2886] Data 0.000 (0.001) Elapsed 11m 21s (remain 18m 24s) Loss: 0.2991(0.2992) Grad: 1480.4448  \n",
      "Epoch: [2][1200/2886] Data 0.000 (0.001) Elapsed 12m 23s (remain 17m 22s) Loss: 0.2861(0.3000) Grad: 2416.7031  \n",
      "Epoch: [2][1300/2886] Data 0.000 (0.001) Elapsed 13m 25s (remain 16m 21s) Loss: 0.3835(0.2987) Grad: 2168.0911  \n",
      "Epoch: [2][1400/2886] Data 0.000 (0.001) Elapsed 14m 27s (remain 15m 19s) Loss: 0.3193(0.2998) Grad: 1505.8988  \n",
      "Epoch: [2][1500/2886] Data 0.000 (0.001) Elapsed 15m 30s (remain 14m 18s) Loss: 0.3567(0.2991) Grad: 1085.5042  \n",
      "Epoch: [2][1600/2886] Data 0.000 (0.001) Elapsed 16m 33s (remain 13m 17s) Loss: 0.2770(0.2990) Grad: 1262.0922  \n",
      "Epoch: [2][1700/2886] Data 0.000 (0.001) Elapsed 17m 36s (remain 12m 15s) Loss: 0.2239(0.2991) Grad: 1462.0535  \n",
      "Epoch: [2][1800/2886] Data 0.000 (0.001) Elapsed 18m 39s (remain 11m 14s) Loss: 0.2345(0.2991) Grad: 1034.7794  \n",
      "Epoch: [2][1900/2886] Data 0.000 (0.001) Elapsed 19m 42s (remain 10m 12s) Loss: 0.2093(0.2992) Grad: 485.7703  \n",
      "Epoch: [2][2000/2886] Data 0.000 (0.001) Elapsed 20m 44s (remain 9m 10s) Loss: 0.2409(0.2990) Grad: 1269.7512  \n",
      "Epoch: [2][2100/2886] Data 0.000 (0.001) Elapsed 21m 46s (remain 8m 8s) Loss: 0.4319(0.2989) Grad: 1293.0890  \n",
      "Epoch: [2][2200/2886] Data 0.000 (0.001) Elapsed 22m 48s (remain 7m 5s) Loss: 0.4028(0.2993) Grad: 1165.6597  \n",
      "Epoch: [2][2300/2886] Data 0.000 (0.001) Elapsed 23m 50s (remain 6m 3s) Loss: 0.2350(0.2992) Grad: 598.3737  \n",
      "Epoch: [2][2400/2886] Data 0.000 (0.001) Elapsed 24m 52s (remain 5m 1s) Loss: 0.4106(0.2993) Grad: 1195.4238  \n",
      "Epoch: [2][2500/2886] Data 0.000 (0.001) Elapsed 25m 54s (remain 3m 59s) Loss: 0.5004(0.2996) Grad: 1491.0920  \n",
      "Epoch: [2][2600/2886] Data 0.000 (0.001) Elapsed 26m 55s (remain 2m 57s) Loss: 0.2700(0.2991) Grad: 713.0679  \n",
      "Epoch: [2][2700/2886] Data 0.000 (0.001) Elapsed 27m 57s (remain 1m 54s) Loss: 0.2306(0.2994) Grad: 732.9901  \n",
      "Epoch: [2][2800/2886] Data 0.000 (0.001) Elapsed 28m 59s (remain 0m 52s) Loss: 0.2774(0.2993) Grad: 400.3939  \n",
      "Epoch: [2][2885/2886] Data 0.000 (0.001) Elapsed 29m 51s (remain 0m 0s) Loss: 0.3687(0.2993) Grad: 878.1348  \n",
      "EVAL: [0/360] Data 2.678 (2.678) Elapsed 0m 2s (remain 17m 27s) Loss: 0.2601(0.2601) \n",
      "EVAL: [100/360] Data 2.070 (0.531) Elapsed 1m 14s (remain 3m 11s) Loss: 0.3500(0.2984) \n",
      "EVAL: [200/360] Data 0.698 (0.517) Elapsed 2m 24s (remain 1m 54s) Loss: 0.2602(0.2984) \n",
      "EVAL: [300/360] Data 0.003 (0.514) Elapsed 3m 34s (remain 0m 42s) Loss: 0.2542(0.2977) \n",
      "EVAL: [359/360] Data 0.000 (0.508) Elapsed 4m 14s (remain 0m 0s) Loss: 0.2223(0.2972) \n",
      "EVAL: [0/78] Data 2.863 (2.863) Elapsed 0m 3s (remain 4m 1s) Loss: 0.2697(0.2697) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.2993  avg_val_loss: 0.2972  time: 2104s\n",
      "Epoch 2 - test_fold_avg_val_loss: 0.3118\n",
      "Epoch 2 - Score: 0.4670  Scores: [0.4249 0.4459 0.5547 0.4182 0.4367 0.5104 0.3923 0.4835 0.5181 0.4954\n",
      " 0.4564]\n",
      "Epoch 2 - Save Best Loss: 0.2972 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.000 (0.538) Elapsed 0m 57s (remain 0m 0s) Loss: 0.3770(0.3118) \n",
      "Epoch: [3][0/2886] Data 1.615 (1.615) Elapsed 0m 2s (remain 125m 24s) Loss: 0.2043(0.2043) Grad: nan  \n",
      "Epoch: [3][100/2886] Data 0.000 (0.016) Elapsed 1m 7s (remain 30m 50s) Loss: 0.4203(0.3021) Grad: 4374.8091  \n",
      "Epoch: [3][200/2886] Data 0.000 (0.008) Elapsed 2m 10s (remain 29m 0s) Loss: 0.3368(0.3010) Grad: 2067.6162  \n",
      "Epoch: [3][300/2886] Data 0.000 (0.006) Elapsed 3m 13s (remain 27m 43s) Loss: 0.3655(0.3025) Grad: 2238.9250  \n",
      "Epoch: [3][400/2886] Data 0.000 (0.004) Elapsed 4m 17s (remain 26m 34s) Loss: 0.2736(0.3049) Grad: 1378.1587  \n",
      "Epoch: [3][500/2886] Data 0.000 (0.003) Elapsed 5m 20s (remain 25m 26s) Loss: 0.2690(0.3027) Grad: 1358.5730  \n",
      "Epoch: [3][600/2886] Data 0.000 (0.003) Elapsed 6m 24s (remain 24m 22s) Loss: 0.4727(0.3006) Grad: 3299.8989  \n",
      "Epoch: [3][700/2886] Data 0.000 (0.003) Elapsed 7m 28s (remain 23m 16s) Loss: 0.3026(0.3009) Grad: 1261.8976  \n",
      "Epoch: [3][800/2886] Data 0.000 (0.002) Elapsed 8m 31s (remain 22m 12s) Loss: 0.3770(0.3004) Grad: 2497.8386  \n",
      "Epoch: [3][900/2886] Data 0.000 (0.002) Elapsed 9m 36s (remain 21m 9s) Loss: 0.3744(0.3000) Grad: 1499.2236  \n",
      "Epoch: [3][1000/2886] Data 0.000 (0.002) Elapsed 10m 39s (remain 20m 4s) Loss: 0.2759(0.2991) Grad: 1038.6732  \n",
      "Epoch: [3][1100/2886] Data 0.000 (0.002) Elapsed 11m 42s (remain 18m 59s) Loss: 0.2897(0.2992) Grad: 564.8577  \n",
      "Epoch: [3][1200/2886] Data 0.000 (0.002) Elapsed 12m 45s (remain 17m 53s) Loss: 0.3547(0.2988) Grad: 871.9567  \n",
      "Epoch: [3][1300/2886] Data 0.000 (0.001) Elapsed 13m 48s (remain 16m 49s) Loss: 0.3131(0.2983) Grad: 827.3599  \n",
      "Epoch: [3][1400/2886] Data 0.000 (0.001) Elapsed 14m 51s (remain 15m 45s) Loss: 0.2637(0.2988) Grad: 552.4997  \n",
      "Epoch: [3][1500/2886] Data 0.000 (0.001) Elapsed 15m 54s (remain 14m 41s) Loss: 0.2985(0.2983) Grad: 736.9714  \n",
      "Epoch: [3][1600/2886] Data 0.000 (0.001) Elapsed 16m 58s (remain 13m 37s) Loss: 0.2918(0.2985) Grad: 763.4870  \n",
      "Epoch: [3][1700/2886] Data 0.000 (0.001) Elapsed 18m 2s (remain 12m 34s) Loss: 0.2476(0.2985) Grad: 406.1656  \n",
      "Epoch: [3][1800/2886] Data 0.000 (0.001) Elapsed 19m 6s (remain 11m 30s) Loss: 0.3334(0.2988) Grad: 324.6212  \n",
      "Epoch: [3][1900/2886] Data 0.000 (0.001) Elapsed 20m 9s (remain 10m 26s) Loss: 0.3517(0.2995) Grad: 262.9962  \n",
      "Epoch: [3][2000/2886] Data 0.001 (0.001) Elapsed 21m 12s (remain 9m 22s) Loss: 0.3623(0.2997) Grad: 587.2375  \n",
      "Epoch: [3][2100/2886] Data 0.000 (0.001) Elapsed 22m 15s (remain 8m 19s) Loss: 0.3027(0.2996) Grad: 387.1624  \n",
      "Epoch: [3][2200/2886] Data 0.000 (0.001) Elapsed 23m 19s (remain 7m 15s) Loss: 0.3221(0.2987) Grad: 521.7103  \n",
      "Epoch: [3][2300/2886] Data 0.000 (0.001) Elapsed 24m 23s (remain 6m 12s) Loss: 0.2738(0.2988) Grad: 270.1230  \n",
      "Epoch: [3][2400/2886] Data 0.000 (0.001) Elapsed 25m 26s (remain 5m 8s) Loss: 0.1952(0.2992) Grad: 360.9081  \n",
      "Epoch: [3][2500/2886] Data 0.000 (0.001) Elapsed 26m 29s (remain 4m 4s) Loss: 0.2182(0.2998) Grad: 351.8647  \n",
      "Epoch: [3][2600/2886] Data 0.000 (0.001) Elapsed 27m 33s (remain 3m 1s) Loss: 0.2530(0.2998) Grad: 259.3560  \n",
      "Epoch: [3][2700/2886] Data 0.000 (0.001) Elapsed 28m 37s (remain 1m 57s) Loss: 0.3392(0.2997) Grad: 360.1475  \n",
      "Epoch: [3][2800/2886] Data 0.000 (0.001) Elapsed 29m 42s (remain 0m 54s) Loss: 0.2113(0.2997) Grad: 372.8466  \n",
      "Epoch: [3][2885/2886] Data 0.000 (0.001) Elapsed 30m 35s (remain 0m 0s) Loss: 0.2798(0.2995) Grad: 385.9921  \n",
      "EVAL: [0/360] Data 3.316 (3.316) Elapsed 0m 3s (remain 21m 7s) Loss: 0.2555(0.2555) \n",
      "EVAL: [100/360] Data 2.637 (0.569) Elapsed 1m 19s (remain 3m 22s) Loss: 0.3505(0.2982) \n",
      "EVAL: [200/360] Data 1.034 (0.554) Elapsed 2m 33s (remain 2m 1s) Loss: 0.2561(0.2978) \n",
      "EVAL: [300/360] Data 2.023 (0.552) Elapsed 3m 49s (remain 0m 44s) Loss: 0.2515(0.2971) \n",
      "EVAL: [359/360] Data 0.000 (0.544) Elapsed 4m 30s (remain 0m 0s) Loss: 0.2213(0.2965) \n",
      "EVAL: [0/78] Data 3.373 (3.373) Elapsed 0m 3s (remain 4m 47s) Loss: 0.2618(0.2618) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2995  avg_val_loss: 0.2965  time: 2168s\n",
      "Epoch 3 - test_fold_avg_val_loss: 0.3110\n",
      "Epoch 3 - Score: 0.4867  Scores: [0.5648 0.5183 0.4837 0.4112 0.4918 0.4901 0.5009 0.4937 0.4918 0.5008\n",
      " 0.4067]\n",
      "Epoch 3 - Save Best Loss: 0.2965 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.000 (0.582) Elapsed 1m 1s (remain 0m 0s) Loss: 0.3851(0.3110) \n",
      "Epoch: [4][0/2886] Data 1.512 (1.512) Elapsed 0m 2s (remain 131m 27s) Loss: 0.2940(0.2940) Grad: nan  \n",
      "Epoch: [4][100/2886] Data 0.000 (0.015) Elapsed 1m 10s (remain 32m 20s) Loss: 0.3531(0.3120) Grad: 1848.3649  \n",
      "Epoch: [4][200/2886] Data 0.000 (0.008) Elapsed 2m 16s (remain 30m 28s) Loss: 0.3248(0.3010) Grad: 1554.6338  \n",
      "Epoch: [4][300/2886] Data 0.000 (0.005) Elapsed 3m 22s (remain 29m 3s) Loss: 0.2566(0.2950) Grad: 474.6259  \n",
      "Epoch: [4][400/2886] Data 0.000 (0.004) Elapsed 4m 29s (remain 27m 49s) Loss: 0.3806(0.2960) Grad: 1099.2212  \n",
      "Epoch: [4][500/2886] Data 0.000 (0.003) Elapsed 5m 34s (remain 26m 34s) Loss: 0.2046(0.2962) Grad: 703.5767  \n",
      "Epoch: [4][600/2886] Data 0.000 (0.003) Elapsed 6m 40s (remain 25m 23s) Loss: 0.2887(0.2989) Grad: 428.2557  \n",
      "Epoch: [4][700/2886] Data 0.000 (0.002) Elapsed 7m 46s (remain 24m 15s) Loss: 0.2185(0.2978) Grad: 358.9857  \n",
      "Epoch: [4][800/2886] Data 0.000 (0.002) Elapsed 8m 55s (remain 23m 13s) Loss: 0.4313(0.2998) Grad: 759.0094  \n",
      "Epoch: [4][900/2886] Data 0.000 (0.002) Elapsed 10m 3s (remain 22m 8s) Loss: 0.2779(0.2993) Grad: 1356.0188  \n",
      "Epoch: [4][1000/2886] Data 0.000 (0.002) Elapsed 11m 10s (remain 21m 1s) Loss: 0.2318(0.2994) Grad: 376.7120  \n",
      "Epoch: [4][1100/2886] Data 0.000 (0.002) Elapsed 12m 17s (remain 19m 55s) Loss: 0.3492(0.2993) Grad: 384.6279  \n",
      "Epoch: [4][1200/2886] Data 0.000 (0.002) Elapsed 13m 24s (remain 18m 48s) Loss: 0.3925(0.2995) Grad: 955.4819  \n",
      "Epoch: [4][1300/2886] Data 0.000 (0.001) Elapsed 14m 31s (remain 17m 41s) Loss: 0.2458(0.3001) Grad: 408.7792  \n",
      "Epoch: [4][1400/2886] Data 0.000 (0.001) Elapsed 15m 37s (remain 16m 33s) Loss: 0.3240(0.3002) Grad: 840.4509  \n",
      "Epoch: [4][1500/2886] Data 0.000 (0.001) Elapsed 16m 44s (remain 15m 27s) Loss: 0.2070(0.3000) Grad: 503.6906  \n",
      "Epoch: [4][1600/2886] Data 0.000 (0.001) Elapsed 17m 52s (remain 14m 20s) Loss: 0.4482(0.2996) Grad: 986.9828  \n",
      "Epoch: [4][1700/2886] Data 0.000 (0.001) Elapsed 18m 59s (remain 13m 13s) Loss: 0.3669(0.2994) Grad: 624.2160  \n",
      "Epoch: [4][1800/2886] Data 0.000 (0.001) Elapsed 20m 6s (remain 12m 7s) Loss: 0.4719(0.2992) Grad: 1146.3656  \n",
      "Epoch: [4][1900/2886] Data 0.005 (0.001) Elapsed 21m 14s (remain 11m 0s) Loss: 0.2983(0.2989) Grad: 340.3372  \n",
      "Epoch: [4][2000/2886] Data 0.000 (0.001) Elapsed 22m 21s (remain 9m 53s) Loss: 0.3756(0.2988) Grad: 610.9078  \n",
      "Epoch: [4][2100/2886] Data 0.000 (0.001) Elapsed 23m 28s (remain 8m 46s) Loss: 0.2969(0.2987) Grad: 628.0073  \n",
      "Epoch: [4][2200/2886] Data 0.000 (0.001) Elapsed 24m 35s (remain 7m 39s) Loss: 0.4070(0.2991) Grad: 727.6656  \n",
      "Epoch: [4][2300/2886] Data 0.000 (0.001) Elapsed 25m 43s (remain 6m 32s) Loss: 0.3007(0.2991) Grad: 1004.5966  \n",
      "Epoch: [4][2400/2886] Data 0.000 (0.001) Elapsed 26m 51s (remain 5m 25s) Loss: 0.2879(0.2989) Grad: 1027.6497  \n",
      "Epoch: [4][2500/2886] Data 0.000 (0.001) Elapsed 27m 59s (remain 4m 18s) Loss: 0.2954(0.2990) Grad: 1257.4031  \n",
      "Epoch: [4][2600/2886] Data 0.000 (0.001) Elapsed 29m 7s (remain 3m 11s) Loss: 0.2721(0.2989) Grad: 1152.1066  \n",
      "Epoch: [4][2700/2886] Data 0.000 (0.001) Elapsed 30m 15s (remain 2m 4s) Loss: 0.3777(0.2988) Grad: 1375.7318  \n",
      "Epoch: [4][2800/2886] Data 0.000 (0.001) Elapsed 31m 22s (remain 0m 57s) Loss: 0.3545(0.2985) Grad: 1044.6771  \n",
      "Epoch: [4][2885/2886] Data 0.000 (0.001) Elapsed 32m 18s (remain 0m 0s) Loss: 0.3289(0.2988) Grad: 1081.3210  \n",
      "EVAL: [0/360] Data 3.559 (3.559) Elapsed 0m 3s (remain 22m 35s) Loss: 0.2760(0.2760) \n",
      "EVAL: [100/360] Data 0.959 (0.588) Elapsed 1m 20s (remain 3m 27s) Loss: 0.4372(0.3285) \n",
      "EVAL: [200/360] Data 0.000 (0.578) Elapsed 2m 38s (remain 2m 5s) Loss: 0.2849(0.3287) \n",
      "EVAL: [300/360] Data 0.000 (0.576) Elapsed 3m 56s (remain 0m 46s) Loss: 0.2692(0.3274) \n",
      "EVAL: [359/360] Data 0.000 (0.567) Elapsed 4m 39s (remain 0m 0s) Loss: 0.2502(0.3270) \n",
      "EVAL: [0/78] Data 3.204 (3.204) Elapsed 0m 3s (remain 4m 24s) Loss: 0.2581(0.2581) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2988  avg_val_loss: 0.3270  time: 2282s\n",
      "Epoch 4 - test_fold_avg_val_loss: 0.3468\n",
      "Epoch 4 - Score: 0.5102  Scores: [0.5076 0.593  0.4497 0.496  0.5563 0.4193 0.5632 0.5495 0.473  0.4982\n",
      " 0.5067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.000 (0.598) Elapsed 1m 2s (remain 0m 0s) Loss: 0.4618(0.3468) \n",
      "Epoch     4: reducing learning rate of group 0 to 3.0000e-04.\n",
      "Epoch: [5][0/2886] Data 1.913 (1.913) Elapsed 0m 2s (remain 144m 1s) Loss: 0.3627(0.3627) Grad: nan  \n",
      "Epoch: [5][100/2886] Data 0.000 (0.019) Elapsed 1m 10s (remain 32m 34s) Loss: 0.2955(0.2899) Grad: 931.6432  \n",
      "Epoch: [5][200/2886] Data 0.000 (0.010) Elapsed 2m 17s (remain 30m 35s) Loss: 0.2156(0.3020) Grad: 1398.7312  \n",
      "Epoch: [5][300/2886] Data 0.000 (0.007) Elapsed 3m 23s (remain 29m 5s) Loss: 0.2595(0.2979) Grad: 1048.1196  \n",
      "Epoch: [5][400/2886] Data 0.000 (0.005) Elapsed 4m 29s (remain 27m 51s) Loss: 0.2067(0.2984) Grad: 1295.3871  \n",
      "Epoch: [5][500/2886] Data 0.000 (0.004) Elapsed 5m 36s (remain 26m 39s) Loss: 0.4341(0.2977) Grad: 3445.2251  \n",
      "Epoch: [5][600/2886] Data 0.000 (0.003) Elapsed 6m 42s (remain 25m 31s) Loss: 0.2661(0.2976) Grad: 903.4189  \n",
      "Epoch: [5][700/2886] Data 0.000 (0.003) Elapsed 7m 49s (remain 24m 22s) Loss: 0.2890(0.2973) Grad: 991.2248  \n",
      "Epoch: [5][800/2886] Data 0.000 (0.003) Elapsed 8m 55s (remain 23m 13s) Loss: 0.4162(0.2972) Grad: 1862.0089  \n",
      "Epoch: [5][900/2886] Data 0.000 (0.002) Elapsed 10m 1s (remain 22m 6s) Loss: 0.2167(0.2971) Grad: 501.1844  \n",
      "Epoch: [5][1000/2886] Data 0.000 (0.002) Elapsed 11m 6s (remain 20m 56s) Loss: 0.2727(0.2976) Grad: 302.3806  \n",
      "Epoch: [5][1100/2886] Data 0.000 (0.002) Elapsed 12m 13s (remain 19m 48s) Loss: 0.3152(0.2972) Grad: 575.5203  \n",
      "Epoch: [5][1200/2886] Data 0.000 (0.002) Elapsed 13m 19s (remain 18m 41s) Loss: 0.2762(0.2976) Grad: 435.0150  \n",
      "Epoch: [5][1300/2886] Data 0.000 (0.002) Elapsed 14m 25s (remain 17m 34s) Loss: 0.2869(0.2981) Grad: 419.0612  \n",
      "Epoch: [5][1400/2886] Data 0.000 (0.002) Elapsed 15m 31s (remain 16m 27s) Loss: 0.3363(0.2989) Grad: 596.5967  \n",
      "Epoch: [5][1500/2886] Data 0.000 (0.001) Elapsed 16m 36s (remain 15m 19s) Loss: 0.3315(0.2998) Grad: 295.8674  \n",
      "Epoch: [5][1600/2886] Data 0.000 (0.001) Elapsed 17m 41s (remain 14m 12s) Loss: 0.2028(0.2995) Grad: 926.1868  \n",
      "Epoch: [5][1700/2886] Data 0.000 (0.001) Elapsed 18m 47s (remain 13m 5s) Loss: 0.2549(0.2997) Grad: 592.6793  \n",
      "Epoch: [5][1800/2886] Data 0.000 (0.001) Elapsed 19m 53s (remain 11m 58s) Loss: 0.2213(0.2989) Grad: 592.6912  \n",
      "Epoch: [5][1900/2886] Data 0.000 (0.001) Elapsed 20m 58s (remain 10m 52s) Loss: 0.3006(0.2987) Grad: 1578.8884  \n",
      "Epoch: [5][2000/2886] Data 0.000 (0.001) Elapsed 22m 4s (remain 9m 45s) Loss: 0.2532(0.2987) Grad: 514.2304  \n",
      "Epoch: [5][2100/2886] Data 0.000 (0.001) Elapsed 23m 9s (remain 8m 39s) Loss: 0.2797(0.2991) Grad: 495.2929  \n",
      "Epoch: [5][2200/2886] Data 0.000 (0.001) Elapsed 24m 14s (remain 7m 32s) Loss: 0.2771(0.2990) Grad: 1010.6851  \n",
      "Epoch: [5][2300/2886] Data 0.000 (0.001) Elapsed 25m 20s (remain 6m 26s) Loss: 0.1911(0.2988) Grad: 885.0507  \n",
      "Epoch: [5][2400/2886] Data 0.000 (0.001) Elapsed 26m 27s (remain 5m 20s) Loss: 0.4100(0.2988) Grad: 1260.0591  \n",
      "Epoch: [5][2500/2886] Data 0.000 (0.001) Elapsed 27m 34s (remain 4m 14s) Loss: 0.3469(0.2991) Grad: 465.6400  \n",
      "Epoch: [5][2600/2886] Data 0.000 (0.001) Elapsed 28m 39s (remain 3m 8s) Loss: 0.2794(0.2988) Grad: 378.6295  \n",
      "Epoch: [5][2700/2886] Data 0.000 (0.001) Elapsed 29m 44s (remain 2m 2s) Loss: 0.4992(0.2988) Grad: 1394.5073  \n",
      "Epoch: [5][2800/2886] Data 0.000 (0.001) Elapsed 30m 50s (remain 0m 56s) Loss: 0.3352(0.2984) Grad: 1180.4927  \n",
      "Epoch: [5][2885/2886] Data 0.000 (0.001) Elapsed 31m 44s (remain 0m 0s) Loss: 0.3982(0.2982) Grad: 1390.2365  \n",
      "EVAL: [0/360] Data 3.469 (3.469) Elapsed 0m 3s (remain 22m 13s) Loss: 0.2582(0.2582) \n",
      "EVAL: [100/360] Data 2.460 (0.595) Elapsed 1m 21s (remain 3m 27s) Loss: 0.3478(0.2984) \n",
      "EVAL: [200/360] Data 0.273 (0.568) Elapsed 2m 36s (remain 2m 4s) Loss: 0.2565(0.3031) \n",
      "EVAL: [300/360] Data 0.000 (0.564) Elapsed 3m 54s (remain 0m 45s) Loss: 0.2525(0.3054) \n",
      "EVAL: [359/360] Data 0.000 (0.558) Elapsed 4m 37s (remain 0m 0s) Loss: 0.2204(0.3034) \n",
      "EVAL: [0/78] Data 2.811 (2.811) Elapsed 0m 3s (remain 3m 55s) Loss: 0.2638(0.2638) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2982  avg_val_loss: 0.3034  time: 2245s\n",
      "Epoch 5 - test_fold_avg_val_loss: 0.3151\n",
      "Epoch 5 - Score: 0.4838  Scores: [0.4024 0.5279 0.505  0.4964 0.4081 0.5802 0.4521 0.5328 0.4947 0.4724\n",
      " 0.4503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.000 (0.587) Elapsed 1m 1s (remain 0m 0s) Loss: 0.3805(0.3151) \n",
      "Epoch     5: reducing learning rate of group 0 to 3.0000e-05.\n",
      "Epoch: [6][0/2886] Data 1.820 (1.820) Elapsed 0m 3s (remain 159m 4s) Loss: 0.2311(0.2311) Grad: 6005.8550  \n",
      "Epoch: [6][100/2886] Data 0.000 (0.018) Elapsed 1m 10s (remain 32m 20s) Loss: 0.2254(0.2981) Grad: 959.8301  \n",
      "Epoch: [6][200/2886] Data 0.000 (0.009) Elapsed 2m 17s (remain 30m 40s) Loss: 0.3775(0.3054) Grad: 1647.7980  \n",
      "Epoch: [6][300/2886] Data 0.000 (0.006) Elapsed 3m 25s (remain 29m 20s) Loss: 0.2310(0.3078) Grad: 1258.9050  \n",
      "Epoch: [6][400/2886] Data 0.000 (0.005) Elapsed 4m 31s (remain 28m 0s) Loss: 0.2436(0.3053) Grad: 1169.2052  \n",
      "Epoch: [6][500/2886] Data 0.000 (0.004) Elapsed 5m 38s (remain 26m 51s) Loss: 0.3642(0.3015) Grad: 1787.6428  \n",
      "Epoch: [6][600/2886] Data 0.000 (0.003) Elapsed 6m 45s (remain 25m 41s) Loss: 0.3029(0.3007) Grad: 1911.0996  \n",
      "Epoch: [6][700/2886] Data 0.000 (0.003) Elapsed 7m 51s (remain 24m 29s) Loss: 0.2145(0.3017) Grad: 1339.5338  \n",
      "Epoch: [6][800/2886] Data 0.000 (0.002) Elapsed 8m 57s (remain 23m 19s) Loss: 0.3120(0.3014) Grad: 1056.4226  \n",
      "Epoch: [6][900/2886] Data 0.000 (0.002) Elapsed 10m 4s (remain 22m 12s) Loss: 0.2574(0.3020) Grad: 918.8120  \n",
      "Epoch: [6][1000/2886] Data 0.000 (0.002) Elapsed 11m 11s (remain 21m 4s) Loss: 0.2556(0.3013) Grad: 1161.8640  \n",
      "Epoch: [6][1100/2886] Data 0.000 (0.002) Elapsed 12m 18s (remain 19m 56s) Loss: 0.2914(0.3010) Grad: 1118.0392  \n",
      "Epoch: [6][1200/2886] Data 0.000 (0.002) Elapsed 13m 24s (remain 18m 49s) Loss: 0.2892(0.2999) Grad: 821.2100  \n",
      "Epoch: [6][1300/2886] Data 0.000 (0.002) Elapsed 14m 31s (remain 17m 41s) Loss: 0.3388(0.2997) Grad: 1587.0509  \n",
      "Epoch: [6][1400/2886] Data 0.000 (0.002) Elapsed 15m 37s (remain 16m 33s) Loss: 0.2928(0.2994) Grad: 1288.5796  \n",
      "Epoch: [6][1500/2886] Data 0.000 (0.001) Elapsed 16m 44s (remain 15m 26s) Loss: 0.2801(0.2985) Grad: 1424.8263  \n",
      "Epoch: [6][1600/2886] Data 0.000 (0.001) Elapsed 17m 50s (remain 14m 19s) Loss: 0.3373(0.2988) Grad: 1054.4863  \n",
      "Epoch: [6][1700/2886] Data 0.000 (0.001) Elapsed 18m 57s (remain 13m 12s) Loss: 0.2510(0.2991) Grad: 1080.8436  \n",
      "Epoch: [6][1800/2886] Data 0.000 (0.001) Elapsed 20m 4s (remain 12m 5s) Loss: 0.5180(0.2989) Grad: 3404.2793  \n",
      "Epoch: [6][1900/2886] Data 0.000 (0.001) Elapsed 21m 10s (remain 10m 58s) Loss: 0.2108(0.2985) Grad: 1451.8597  \n",
      "Epoch: [6][2000/2886] Data 0.000 (0.001) Elapsed 22m 17s (remain 9m 51s) Loss: 0.1974(0.2991) Grad: 1292.7051  \n",
      "Epoch: [6][2100/2886] Data 0.000 (0.001) Elapsed 23m 24s (remain 8m 44s) Loss: 0.3121(0.2987) Grad: 895.0824  \n",
      "Epoch: [6][2200/2886] Data 0.000 (0.001) Elapsed 24m 31s (remain 7m 37s) Loss: 0.1594(0.2985) Grad: 1996.8123  \n",
      "Epoch: [6][2300/2886] Data 0.000 (0.001) Elapsed 25m 38s (remain 6m 31s) Loss: 0.1621(0.2984) Grad: 1827.2859  \n",
      "Epoch: [6][2400/2886] Data 0.000 (0.001) Elapsed 26m 45s (remain 5m 24s) Loss: 0.4657(0.2981) Grad: 2652.1006  \n",
      "Epoch: [6][2500/2886] Data 0.000 (0.001) Elapsed 27m 52s (remain 4m 17s) Loss: 0.2338(0.2983) Grad: 1681.1432  \n",
      "Epoch: [6][2600/2886] Data 0.000 (0.001) Elapsed 29m 0s (remain 3m 10s) Loss: 0.2741(0.2983) Grad: 1261.8064  \n",
      "Epoch: [6][2700/2886] Data 0.000 (0.001) Elapsed 30m 9s (remain 2m 3s) Loss: 0.4650(0.2983) Grad: 3355.4648  \n",
      "Epoch: [6][2800/2886] Data 0.000 (0.001) Elapsed 31m 17s (remain 0m 56s) Loss: 0.3110(0.2984) Grad: 484.5852  \n",
      "Epoch: [6][2885/2886] Data 0.000 (0.001) Elapsed 32m 13s (remain 0m 0s) Loss: 0.2619(0.2981) Grad: 463.6621  \n",
      "EVAL: [0/360] Data 3.165 (3.165) Elapsed 0m 3s (remain 20m 1s) Loss: 0.2585(0.2585) \n",
      "EVAL: [100/360] Data 1.857 (0.595) Elapsed 1m 21s (remain 3m 27s) Loss: 0.3476(0.3766) \n",
      "EVAL: [200/360] Data 0.615 (0.585) Elapsed 2m 40s (remain 2m 6s) Loss: 0.2562(0.4267) \n",
      "EVAL: [300/360] Data 1.790 (0.580) Elapsed 3m 59s (remain 0m 46s) Loss: 0.2521(0.4038) \n",
      "EVAL: [359/360] Data 0.000 (0.571) Elapsed 4m 42s (remain 0m 0s) Loss: 0.2204(0.3992) \n",
      "EVAL: [0/78] Data 2.982 (2.982) Elapsed 0m 3s (remain 4m 13s) Loss: 0.2638(0.2638) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.2981  avg_val_loss: 0.3992  time: 2279s\n",
      "Epoch 6 - test_fold_avg_val_loss: 0.9724\n",
      "Epoch 6 - Score: 0.6029  Scores: [0.5756 0.6513 0.678  0.5876 0.6506 0.4733 0.7068 0.5306 0.559  0.4906\n",
      " 0.7283]\n",
      "Epoch 6 - Save Best Score: 0.6029 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.074 (0.606) Elapsed 1m 3s (remain 0m 0s) Loss: 0.3807(0.9724) \n",
      "Epoch     6: reducing learning rate of group 0 to 3.0000e-06.\n",
      "Epoch: [7][0/2886] Data 1.413 (1.413) Elapsed 0m 3s (remain 154m 55s) Loss: 0.2190(0.2190) Grad: 6605.9248  \n",
      "Epoch: [7][100/2886] Data 0.000 (0.014) Elapsed 1m 13s (remain 33m 39s) Loss: 0.2513(0.2993) Grad: 1254.2385  \n",
      "Epoch: [7][200/2886] Data 0.000 (0.007) Elapsed 2m 22s (remain 31m 40s) Loss: 0.4329(0.2952) Grad: 2364.8252  \n",
      "Epoch: [7][300/2886] Data 0.000 (0.005) Elapsed 3m 30s (remain 30m 11s) Loss: 0.3099(0.2943) Grad: 1236.7094  \n",
      "Epoch: [7][400/2886] Data 0.000 (0.004) Elapsed 4m 39s (remain 28m 52s) Loss: 0.2769(0.2962) Grad: 990.2027  \n",
      "Epoch: [7][500/2886] Data 0.000 (0.003) Elapsed 5m 48s (remain 27m 38s) Loss: 0.1498(0.2959) Grad: 2037.9340  \n",
      "Epoch: [7][600/2886] Data 0.000 (0.003) Elapsed 6m 57s (remain 26m 26s) Loss: 0.2760(0.2961) Grad: 1189.8467  \n",
      "Epoch: [7][700/2886] Data 0.000 (0.002) Elapsed 8m 6s (remain 25m 16s) Loss: 0.2527(0.2964) Grad: 1369.1531  \n",
      "Epoch: [7][800/2886] Data 0.000 (0.002) Elapsed 9m 15s (remain 24m 5s) Loss: 0.3834(0.2962) Grad: 2433.6658  \n",
      "Epoch: [7][900/2886] Data 0.000 (0.002) Elapsed 10m 24s (remain 22m 55s) Loss: 0.2835(0.2959) Grad: 742.7116  \n",
      "Epoch: [7][1000/2886] Data 0.000 (0.002) Elapsed 11m 33s (remain 21m 46s) Loss: 0.3327(0.2954) Grad: 1559.4733  \n",
      "Epoch: [7][1100/2886] Data 0.000 (0.002) Elapsed 12m 42s (remain 20m 35s) Loss: 0.4596(0.2957) Grad: 2533.4097  \n",
      "Epoch: [7][1200/2886] Data 0.000 (0.001) Elapsed 13m 50s (remain 19m 25s) Loss: 0.3589(0.2962) Grad: 1408.8726  \n",
      "Epoch: [7][1300/2886] Data 0.000 (0.001) Elapsed 14m 59s (remain 18m 16s) Loss: 0.2264(0.2966) Grad: 1486.2178  \n",
      "Epoch: [7][1400/2886] Data 0.000 (0.001) Elapsed 16m 7s (remain 17m 5s) Loss: 0.2893(0.2960) Grad: 1364.4174  \n",
      "Epoch: [7][1500/2886] Data 0.000 (0.001) Elapsed 17m 15s (remain 15m 55s) Loss: 0.2410(0.2964) Grad: 1066.2872  \n",
      "Epoch: [7][1600/2886] Data 0.000 (0.001) Elapsed 18m 22s (remain 14m 45s) Loss: 0.3034(0.2960) Grad: 941.2815  \n",
      "Epoch: [7][1700/2886] Data 0.000 (0.001) Elapsed 19m 30s (remain 13m 35s) Loss: 0.2433(0.2958) Grad: 1240.1027  \n",
      "Epoch: [7][1800/2886] Data 0.000 (0.001) Elapsed 20m 38s (remain 12m 25s) Loss: 0.2803(0.2959) Grad: 1147.4219  \n",
      "Epoch: [7][1900/2886] Data 0.000 (0.001) Elapsed 21m 46s (remain 11m 16s) Loss: 0.2682(0.2958) Grad: 1325.4078  \n",
      "Epoch: [7][2000/2886] Data 0.000 (0.001) Elapsed 22m 53s (remain 10m 7s) Loss: 0.2032(0.2961) Grad: 1567.8408  \n",
      "Epoch: [7][2100/2886] Data 0.000 (0.001) Elapsed 24m 2s (remain 8m 59s) Loss: 0.2697(0.2969) Grad: 1293.3418  \n",
      "Epoch: [7][2200/2886] Data 0.000 (0.001) Elapsed 25m 9s (remain 7m 49s) Loss: 0.2749(0.2969) Grad: 1067.7980  \n",
      "Epoch: [7][2300/2886] Data 0.000 (0.001) Elapsed 26m 18s (remain 6m 41s) Loss: 0.2519(0.2971) Grad: 1129.4509  \n",
      "Epoch: [7][2400/2886] Data 0.000 (0.001) Elapsed 27m 25s (remain 5m 32s) Loss: 0.3497(0.2972) Grad: 610.2845  \n",
      "Epoch: [7][2500/2886] Data 0.000 (0.001) Elapsed 28m 31s (remain 4m 23s) Loss: 0.2803(0.2973) Grad: 290.8739  \n",
      "Epoch: [7][2600/2886] Data 0.000 (0.001) Elapsed 29m 37s (remain 3m 14s) Loss: 0.2263(0.2972) Grad: 709.5838  \n",
      "Epoch: [7][2700/2886] Data 0.000 (0.001) Elapsed 30m 45s (remain 2m 6s) Loss: 0.2752(0.2972) Grad: 669.3071  \n",
      "Epoch: [7][2800/2886] Data 0.000 (0.001) Elapsed 31m 52s (remain 0m 58s) Loss: 0.4241(0.2974) Grad: 1788.4115  \n",
      "Epoch: [7][2885/2886] Data 0.000 (0.001) Elapsed 32m 49s (remain 0m 0s) Loss: 0.3414(0.2974) Grad: 839.7581  \n",
      "EVAL: [0/360] Data 3.065 (3.065) Elapsed 0m 3s (remain 19m 32s) Loss: 0.2583(0.2583) \n",
      "EVAL: [100/360] Data 2.252 (0.601) Elapsed 1m 22s (remain 3m 31s) Loss: 0.3471(0.4269) \n",
      "EVAL: [200/360] Data 1.801 (0.591) Elapsed 2m 41s (remain 2m 7s) Loss: 0.2557(0.4685) \n",
      "EVAL: [300/360] Data 1.119 (0.582) Elapsed 3m 59s (remain 0m 46s) Loss: 0.2520(0.4306) \n",
      "EVAL: [359/360] Data 0.000 (0.576) Elapsed 4m 43s (remain 0m 0s) Loss: 0.2206(0.4237) \n",
      "EVAL: [0/78] Data 3.276 (3.276) Elapsed 0m 3s (remain 4m 31s) Loss: 0.2639(0.2639) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.2974  avg_val_loss: 0.4237  time: 2316s\n",
      "Epoch 7 - test_fold_avg_val_loss: 1.1758\n",
      "Epoch 7 - Score: 0.6116  Scores: [0.5726 0.6696 0.6927 0.6051 0.6565 0.493  0.7152 0.5323 0.5511 0.5038\n",
      " 0.7354]\n",
      "Epoch 7 - Save Best Score: 0.6116 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.271 (0.598) Elapsed 1m 2s (remain 0m 0s) Loss: 0.3805(1.1758) \n",
      "Epoch     7: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch: [8][0/2886] Data 2.274 (2.274) Elapsed 0m 3s (remain 171m 27s) Loss: 0.3258(0.3258) Grad: nan  \n",
      "Epoch: [8][100/2886] Data 0.000 (0.023) Elapsed 1m 12s (remain 33m 29s) Loss: 0.2983(0.3012) Grad: 859.6932  \n",
      "Epoch: [8][200/2886] Data 0.000 (0.012) Elapsed 2m 21s (remain 31m 29s) Loss: 0.2362(0.3016) Grad: 959.1054  \n",
      "Epoch: [8][300/2886] Data 0.000 (0.008) Elapsed 3m 29s (remain 30m 1s) Loss: 0.2569(0.2975) Grad: 1452.6658  \n",
      "Epoch: [8][400/2886] Data 0.000 (0.006) Elapsed 4m 37s (remain 28m 40s) Loss: 0.2937(0.2977) Grad: 1178.2643  \n",
      "Epoch: [8][500/2886] Data 0.000 (0.005) Elapsed 5m 46s (remain 27m 28s) Loss: 0.2382(0.2982) Grad: 803.3138  \n",
      "Epoch: [8][600/2886] Data 0.000 (0.004) Elapsed 6m 54s (remain 26m 14s) Loss: 0.3185(0.2971) Grad: 1065.7411  \n",
      "Epoch: [8][700/2886] Data 0.000 (0.003) Elapsed 8m 2s (remain 25m 3s) Loss: 0.2572(0.2968) Grad: 836.7836  \n",
      "Epoch: [8][800/2886] Data 0.000 (0.003) Elapsed 9m 11s (remain 23m 54s) Loss: 0.2409(0.2969) Grad: 940.7638  \n",
      "Epoch: [8][900/2886] Data 0.000 (0.003) Elapsed 10m 19s (remain 22m 43s) Loss: 0.1778(0.2969) Grad: 1742.5439  \n",
      "Epoch: [8][1000/2886] Data 0.000 (0.002) Elapsed 11m 28s (remain 21m 36s) Loss: 0.2097(0.2966) Grad: 1829.5179  \n",
      "Epoch: [8][1100/2886] Data 0.000 (0.002) Elapsed 12m 37s (remain 20m 27s) Loss: 0.2932(0.2968) Grad: 1134.3864  \n",
      "Epoch: [8][1200/2886] Data 0.000 (0.002) Elapsed 13m 45s (remain 19m 18s) Loss: 0.2314(0.2978) Grad: 1348.9652  \n",
      "Epoch: [8][1300/2886] Data 0.000 (0.002) Elapsed 14m 53s (remain 18m 8s) Loss: 0.3185(0.2983) Grad: 1322.0858  \n",
      "Epoch: [8][1400/2886] Data 0.000 (0.002) Elapsed 16m 1s (remain 16m 58s) Loss: 0.3720(0.2983) Grad: 1925.7433  \n",
      "Epoch: [8][1500/2886] Data 0.000 (0.002) Elapsed 17m 9s (remain 15m 49s) Loss: 0.1965(0.2975) Grad: 1445.8406  \n",
      "Epoch: [8][1600/2886] Data 0.000 (0.002) Elapsed 18m 17s (remain 14m 40s) Loss: 0.3119(0.2973) Grad: 1132.4069  \n",
      "Epoch: [8][1700/2886] Data 0.000 (0.002) Elapsed 19m 23s (remain 13m 30s) Loss: 0.1973(0.2967) Grad: 1409.1611  \n",
      "Epoch: [8][1800/2886] Data 0.000 (0.001) Elapsed 20m 30s (remain 12m 21s) Loss: 0.2666(0.2965) Grad: 1090.9852  \n",
      "Epoch: [8][1900/2886] Data 0.000 (0.001) Elapsed 21m 37s (remain 11m 12s) Loss: 0.2684(0.2964) Grad: 1260.8627  \n",
      "Epoch: [8][2000/2886] Data 0.000 (0.001) Elapsed 22m 44s (remain 10m 3s) Loss: 0.4659(0.2965) Grad: 2260.4141  \n",
      "Epoch: [8][2100/2886] Data 0.000 (0.001) Elapsed 23m 51s (remain 8m 54s) Loss: 0.4011(0.2973) Grad: 2799.8340  \n",
      "Epoch: [8][2200/2886] Data 0.000 (0.001) Elapsed 24m 58s (remain 7m 46s) Loss: 0.2034(0.2971) Grad: 1422.1797  \n",
      "Epoch: [8][2300/2886] Data 0.000 (0.001) Elapsed 26m 6s (remain 6m 38s) Loss: 0.5226(0.2968) Grad: 3944.1587  \n",
      "Epoch: [8][2400/2886] Data 0.000 (0.001) Elapsed 27m 14s (remain 5m 30s) Loss: 0.3863(0.2970) Grad: 1843.6785  \n",
      "Epoch: [8][2500/2886] Data 0.000 (0.001) Elapsed 28m 20s (remain 4m 21s) Loss: 0.3807(0.2973) Grad: 885.7607  \n",
      "Epoch: [8][2600/2886] Data 0.000 (0.001) Elapsed 29m 27s (remain 3m 13s) Loss: 0.3202(0.2975) Grad: 823.2242  \n",
      "Epoch: [8][2700/2886] Data 0.000 (0.001) Elapsed 30m 34s (remain 2m 5s) Loss: 0.3871(0.2975) Grad: 1619.3712  \n",
      "Epoch: [8][2800/2886] Data 0.000 (0.001) Elapsed 31m 41s (remain 0m 57s) Loss: 0.3097(0.2972) Grad: 732.4507  \n",
      "Epoch: [8][2885/2886] Data 0.000 (0.001) Elapsed 32m 36s (remain 0m 0s) Loss: 0.2698(0.2973) Grad: 583.2446  \n",
      "EVAL: [0/360] Data 3.491 (3.491) Elapsed 0m 3s (remain 22m 12s) Loss: 0.2582(0.2582) \n",
      "EVAL: [100/360] Data 1.469 (0.587) Elapsed 1m 20s (remain 3m 27s) Loss: 0.3470(0.7904) \n",
      "EVAL: [200/360] Data 0.254 (0.572) Elapsed 2m 37s (remain 2m 4s) Loss: 0.2556(0.7745) \n",
      "EVAL: [300/360] Data 1.018 (0.573) Elapsed 3m 56s (remain 0m 46s) Loss: 0.2518(0.7014) \n",
      "EVAL: [359/360] Data 0.000 (0.565) Elapsed 4m 39s (remain 0m 0s) Loss: 0.2205(0.7001) \n",
      "EVAL: [0/78] Data 3.311 (3.311) Elapsed 0m 3s (remain 4m 32s) Loss: 0.2639(0.2639) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.2973  avg_val_loss: 0.7001  time: 2298s\n",
      "Epoch 8 - test_fold_avg_val_loss: 2.1195\n",
      "Epoch 8 - Score: 0.6174  Scores: [0.5756 0.6648 0.6951 0.6063 0.6607 0.5458 0.7092 0.5347 0.5571 0.5156\n",
      " 0.7261]\n",
      "Epoch 8 - Save Best Score: 0.6174 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.196 (0.599) Elapsed 1m 2s (remain 0m 0s) Loss: 0.3789(2.1195) \n",
      "Epoch: [9][0/2886] Data 1.456 (1.456) Elapsed 0m 3s (remain 152m 55s) Loss: 0.2618(0.2618) Grad: 3919.2524  \n",
      "Epoch: [9][100/2886] Data 0.000 (0.015) Elapsed 1m 11s (remain 33m 2s) Loss: 0.2640(0.3020) Grad: 845.6094  \n",
      "Epoch: [9][200/2886] Data 0.000 (0.008) Elapsed 2m 20s (remain 31m 10s) Loss: 0.2729(0.3042) Grad: 731.0513  \n",
      "Epoch: [9][300/2886] Data 0.000 (0.005) Elapsed 3m 28s (remain 29m 47s) Loss: 0.2981(0.3027) Grad: 1132.9706  \n",
      "Epoch: [9][400/2886] Data 0.000 (0.004) Elapsed 4m 35s (remain 28m 30s) Loss: 0.3858(0.3036) Grad: 2935.3091  \n",
      "Epoch: [9][500/2886] Data 0.000 (0.003) Elapsed 5m 44s (remain 27m 21s) Loss: 0.2484(0.3016) Grad: 1428.9496  \n",
      "Epoch: [9][600/2886] Data 0.000 (0.003) Elapsed 6m 53s (remain 26m 10s) Loss: 0.3261(0.3014) Grad: 1045.2021  \n",
      "Epoch: [9][700/2886] Data 0.000 (0.002) Elapsed 8m 1s (remain 25m 0s) Loss: 0.2678(0.2998) Grad: 1088.1326  \n",
      "Epoch: [9][800/2886] Data 0.000 (0.002) Elapsed 9m 9s (remain 23m 50s) Loss: 0.3314(0.3001) Grad: 1504.2075  \n",
      "Epoch: [9][900/2886] Data 0.000 (0.002) Elapsed 10m 17s (remain 22m 40s) Loss: 0.3148(0.2990) Grad: 887.0568  \n",
      "Epoch: [9][1000/2886] Data 0.000 (0.002) Elapsed 11m 24s (remain 21m 29s) Loss: 0.2423(0.2986) Grad: 1060.2996  \n",
      "Epoch: [9][1100/2886] Data 0.000 (0.002) Elapsed 12m 35s (remain 20m 24s) Loss: 0.2821(0.2982) Grad: 1029.1721  \n",
      "Epoch: [9][1200/2886] Data 0.000 (0.001) Elapsed 13m 44s (remain 19m 16s) Loss: 0.3058(0.2975) Grad: 809.2725  \n",
      "Epoch: [9][1300/2886] Data 0.000 (0.001) Elapsed 14m 52s (remain 18m 7s) Loss: 0.3201(0.2979) Grad: 1079.3708  \n",
      "Epoch: [9][1400/2886] Data 0.000 (0.001) Elapsed 16m 1s (remain 16m 59s) Loss: 0.3014(0.2983) Grad: 1072.3901  \n",
      "Epoch: [9][1500/2886] Data 0.000 (0.001) Elapsed 17m 8s (remain 15m 49s) Loss: 0.3311(0.2986) Grad: 1141.7284  \n",
      "Epoch: [9][1600/2886] Data 0.000 (0.001) Elapsed 18m 16s (remain 14m 40s) Loss: 0.3496(0.2987) Grad: 1562.8658  \n",
      "Epoch: [9][1700/2886] Data 0.000 (0.001) Elapsed 19m 25s (remain 13m 31s) Loss: 0.2762(0.2978) Grad: 1384.6619  \n",
      "Epoch: [9][1800/2886] Data 0.000 (0.001) Elapsed 20m 33s (remain 12m 23s) Loss: 0.2879(0.2980) Grad: 2438.8333  \n",
      "Epoch: [9][1900/2886] Data 0.000 (0.001) Elapsed 21m 41s (remain 11m 14s) Loss: 0.3111(0.2979) Grad: 1049.2571  \n",
      "Epoch: [9][2000/2886] Data 0.000 (0.001) Elapsed 22m 49s (remain 10m 5s) Loss: 0.3462(0.2981) Grad: 1402.5660  \n",
      "Epoch: [9][2100/2886] Data 0.000 (0.001) Elapsed 23m 56s (remain 8m 56s) Loss: 0.2689(0.2982) Grad: 1335.2697  \n",
      "Epoch: [9][2200/2886] Data 0.000 (0.001) Elapsed 25m 3s (remain 7m 48s) Loss: 0.3620(0.2978) Grad: 2603.9324  \n",
      "Epoch: [9][2300/2886] Data 0.000 (0.001) Elapsed 26m 10s (remain 6m 39s) Loss: 0.2732(0.2975) Grad: 991.7139  \n",
      "Epoch: [9][2400/2886] Data 0.000 (0.001) Elapsed 27m 18s (remain 5m 30s) Loss: 0.3515(0.2977) Grad: 1504.3103  \n",
      "Epoch: [9][2500/2886] Data 0.000 (0.001) Elapsed 28m 25s (remain 4m 22s) Loss: 0.3024(0.2973) Grad: 1795.1770  \n",
      "Epoch: [9][2600/2886] Data 0.000 (0.001) Elapsed 29m 32s (remain 3m 14s) Loss: 0.4158(0.2969) Grad: 1936.7393  \n",
      "Epoch: [9][2700/2886] Data 0.000 (0.001) Elapsed 30m 41s (remain 2m 6s) Loss: 0.3765(0.2970) Grad: 1571.8474  \n",
      "Epoch: [9][2800/2886] Data 0.000 (0.001) Elapsed 31m 48s (remain 0m 57s) Loss: 0.2506(0.2970) Grad: 1427.8254  \n",
      "Epoch: [9][2885/2886] Data 0.000 (0.001) Elapsed 32m 43s (remain 0m 0s) Loss: 0.2795(0.2972) Grad: 1101.4932  \n",
      "EVAL: [0/360] Data 3.174 (3.174) Elapsed 0m 3s (remain 20m 18s) Loss: 0.2582(0.2582) \n",
      "EVAL: [100/360] Data 2.117 (0.588) Elapsed 1m 20s (remain 3m 27s) Loss: 0.3469(0.5258) \n",
      "EVAL: [200/360] Data 1.232 (0.571) Elapsed 2m 37s (remain 2m 4s) Loss: 0.2556(0.5751) \n",
      "EVAL: [300/360] Data 1.624 (0.568) Elapsed 3m 54s (remain 0m 46s) Loss: 0.2519(0.5196) \n",
      "EVAL: [359/360] Data 0.000 (0.562) Elapsed 4m 38s (remain 0m 0s) Loss: 0.2206(0.5143) \n",
      "EVAL: [0/78] Data 2.883 (2.883) Elapsed 0m 3s (remain 3m 57s) Loss: 0.2639(0.2639) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.2972  avg_val_loss: 0.5143  time: 2305s\n",
      "Epoch 9 - test_fold_avg_val_loss: 1.4766\n",
      "Epoch 9 - Score: 0.6197  Scores: [0.5718 0.6764 0.6976 0.6068 0.6583 0.5552 0.7147 0.5306 0.5557 0.5143\n",
      " 0.7354]\n",
      "Epoch 9 - Save Best Score: 0.6197 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.169 (0.593) Elapsed 1m 2s (remain 0m 0s) Loss: 0.3796(1.4766) \n",
      "Epoch: [10][0/2886] Data 1.527 (1.527) Elapsed 0m 2s (remain 133m 26s) Loss: 0.2860(0.2860) Grad: nan  \n",
      "Epoch: [10][100/2886] Data 0.000 (0.015) Elapsed 1m 11s (remain 32m 38s) Loss: 0.2854(0.2865) Grad: 1571.6271  \n",
      "Epoch: [10][200/2886] Data 0.000 (0.008) Elapsed 2m 18s (remain 30m 52s) Loss: 0.3968(0.2946) Grad: 2764.3787  \n",
      "Epoch: [10][300/2886] Data 0.000 (0.005) Elapsed 3m 26s (remain 29m 32s) Loss: 0.2841(0.2974) Grad: 948.4014  \n",
      "Epoch: [10][400/2886] Data 0.000 (0.004) Elapsed 4m 33s (remain 28m 12s) Loss: 0.3030(0.2957) Grad: 1203.1260  \n",
      "Epoch: [10][500/2886] Data 0.000 (0.003) Elapsed 5m 40s (remain 27m 0s) Loss: 0.2477(0.2952) Grad: 944.1910  \n",
      "Epoch: [10][600/2886] Data 0.000 (0.003) Elapsed 6m 48s (remain 25m 51s) Loss: 0.3455(0.2961) Grad: 1211.1790  \n",
      "Epoch: [10][700/2886] Data 0.000 (0.002) Elapsed 7m 54s (remain 24m 40s) Loss: 0.2154(0.2961) Grad: 1307.4049  \n",
      "Epoch: [10][800/2886] Data 0.000 (0.002) Elapsed 9m 2s (remain 23m 32s) Loss: 0.2130(0.2947) Grad: 1020.3051  \n",
      "Epoch: [10][900/2886] Data 0.000 (0.002) Elapsed 10m 9s (remain 22m 23s) Loss: 0.3396(0.2956) Grad: 1225.9464  \n",
      "Epoch: [10][1000/2886] Data 0.000 (0.002) Elapsed 11m 16s (remain 21m 13s) Loss: 0.1992(0.2946) Grad: 1398.2363  \n",
      "Epoch: [10][1100/2886] Data 0.000 (0.002) Elapsed 12m 24s (remain 20m 7s) Loss: 0.3737(0.2944) Grad: 1492.6423  \n",
      "Epoch: [10][1200/2886] Data 0.000 (0.002) Elapsed 13m 31s (remain 18m 59s) Loss: 0.3208(0.2948) Grad: 880.4079  \n",
      "Epoch: [10][1300/2886] Data 0.000 (0.001) Elapsed 14m 39s (remain 17m 51s) Loss: 0.3212(0.2939) Grad: 953.6583  \n",
      "Epoch: [10][1400/2886] Data 0.000 (0.001) Elapsed 15m 45s (remain 16m 42s) Loss: 0.2565(0.2941) Grad: 1282.9119  \n",
      "Epoch: [10][1500/2886] Data 0.000 (0.001) Elapsed 16m 53s (remain 15m 34s) Loss: 0.3767(0.2941) Grad: 1889.5995  \n",
      "Epoch: [10][1600/2886] Data 0.000 (0.001) Elapsed 17m 59s (remain 14m 26s) Loss: 0.3361(0.2942) Grad: 1129.1136  \n",
      "Epoch: [10][1700/2886] Data 0.000 (0.001) Elapsed 19m 5s (remain 13m 18s) Loss: 0.2683(0.2946) Grad: 908.0132  \n",
      "Epoch: [10][1800/2886] Data 0.000 (0.001) Elapsed 20m 12s (remain 12m 10s) Loss: 0.2084(0.2950) Grad: 1265.2280  \n",
      "Epoch: [10][1900/2886] Data 0.000 (0.001) Elapsed 21m 19s (remain 11m 3s) Loss: 0.2752(0.2947) Grad: 720.1464  \n",
      "Epoch: [10][2000/2886] Data 0.000 (0.001) Elapsed 22m 27s (remain 9m 55s) Loss: 0.3809(0.2950) Grad: 1314.1132  \n",
      "Epoch: [10][2100/2886] Data 0.000 (0.001) Elapsed 23m 33s (remain 8m 48s) Loss: 0.3608(0.2953) Grad: 2065.0549  \n",
      "Epoch: [10][2200/2886] Data 0.000 (0.001) Elapsed 24m 41s (remain 7m 40s) Loss: 0.3002(0.2957) Grad: 953.7014  \n",
      "Epoch: [10][2300/2886] Data 0.000 (0.001) Elapsed 25m 48s (remain 6m 33s) Loss: 0.2902(0.2958) Grad: 934.0605  \n",
      "Epoch: [10][2400/2886] Data 0.000 (0.001) Elapsed 26m 56s (remain 5m 26s) Loss: 0.3812(0.2962) Grad: 1395.1143  \n",
      "Epoch: [10][2500/2886] Data 0.000 (0.001) Elapsed 28m 4s (remain 4m 19s) Loss: 0.3653(0.2960) Grad: 1210.0343  \n",
      "Epoch: [10][2600/2886] Data 0.000 (0.001) Elapsed 29m 11s (remain 3m 11s) Loss: 0.3995(0.2964) Grad: 2071.6238  \n",
      "Epoch: [10][2700/2886] Data 0.000 (0.001) Elapsed 30m 18s (remain 2m 4s) Loss: 0.2803(0.2966) Grad: 1529.4104  \n",
      "Epoch: [10][2800/2886] Data 0.000 (0.001) Elapsed 31m 26s (remain 0m 57s) Loss: 0.3099(0.2973) Grad: 1607.3926  \n",
      "Epoch: [10][2885/2886] Data 0.000 (0.001) Elapsed 32m 22s (remain 0m 0s) Loss: 0.4593(0.2973) Grad: 2414.0830  \n",
      "EVAL: [0/360] Data 3.413 (3.413) Elapsed 0m 3s (remain 21m 41s) Loss: 0.2582(0.2582) \n",
      "EVAL: [100/360] Data 2.496 (0.569) Elapsed 1m 19s (remain 3m 22s) Loss: 0.3468(0.3799) \n",
      "EVAL: [200/360] Data 2.106 (0.549) Elapsed 2m 33s (remain 2m 1s) Loss: 0.2557(0.3985) \n",
      "EVAL: [300/360] Data 1.896 (0.547) Elapsed 3m 48s (remain 0m 44s) Loss: 0.2519(0.3742) \n",
      "EVAL: [359/360] Data 0.000 (0.537) Elapsed 4m 29s (remain 0m 0s) Loss: 0.2207(0.3697) \n",
      "EVAL: [0/78] Data 2.942 (2.942) Elapsed 0m 3s (remain 4m 6s) Loss: 0.2639(0.2639) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.2973  avg_val_loss: 0.3697  time: 2272s\n",
      "Epoch 10 - test_fold_avg_val_loss: 0.8931\n",
      "Epoch 10 - Score: 0.6197  Scores: [0.5699 0.6759 0.7008 0.6056 0.6591 0.5548 0.7205 0.5242 0.5564 0.5144\n",
      " 0.7352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Data 0.090 (0.567) Elapsed 1m 0s (remain 0m 0s) Loss: 0.3806(0.8931) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.6197  Scores: [0.5718 0.6764 0.6976 0.6068 0.6583 0.5552 0.7147 0.5306 0.5557 0.5143\n",
      " 0.7354]\n",
      "========== CV ==========\n",
      "Score: 0.6197  Scores: [0.5718 0.6764 0.6976 0.6068 0.6583 0.5552 0.7147 0.5306 0.5557 0.5143\n",
      " 0.7354]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if CFG.device == 'TPU':\n",
    "        print('TPU MODE')\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        print('GPU MODE')\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T20:35:29.906082Z",
     "iopub.status.busy": "2021-01-31T20:35:29.905101Z",
     "iopub.status.idle": "2021-01-31T20:35:29.910066Z",
     "shell.execute_reply": "2021-01-31T20:35:29.909191Z"
    },
    "papermill": {
     "duration": 0.250079,
     "end_time": "2021-01-31T20:35:29.910257",
     "exception": false,
     "start_time": "2021-01-31T20:35:29.660178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save as cpu\n",
    "if CFG.device == 'TPU':\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            # best score\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_score_cpu.pth')\n",
    "            # best loss\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_step{CFG.STEP}_best_loss_cpu.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22430.073624,
   "end_time": "2021-01-31T20:35:32.151605",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-31T14:21:42.077981",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04250bf656b04e39952f291e27b2951f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ba59250bba24289b441ffe234ca1da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a45f6a661f7418e9cee798ef5841f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59bf409ee678456c99320e03c9bf9108",
       "placeholder": "​",
       "style": "IPY_MODEL_3d609ddcd36448d8837bf4e0150ce61e",
       "value": "100%"
      }
     },
     "3ad2779948c24a6c92e5a61066072c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d609ddcd36448d8837bf4e0150ce61e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56923221e1b3480794c90f676cf6a5bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed5af00842624a979a085df9a77b44af",
       "placeholder": "​",
       "style": "IPY_MODEL_5e7068520e0e45b18907c3a69d80d0fa",
       "value": " 254M/254M [00:01&lt;00:00, 184MB/s]"
      }
     },
     "59bf409ee678456c99320e03c9bf9108": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a6a471c12d0479294630673baf7bffb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ba59250bba24289b441ffe234ca1da7",
       "max": 266860719,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ad2779948c24a6c92e5a61066072c04",
       "value": 266860719
      }
     },
     "5e7068520e0e45b18907c3a69d80d0fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5f22f6d28a91492298ce6d7b2c83ed38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3a45f6a661f7418e9cee798ef5841f7a",
        "IPY_MODEL_5a6a471c12d0479294630673baf7bffb",
        "IPY_MODEL_56923221e1b3480794c90f676cf6a5bb"
       ],
       "layout": "IPY_MODEL_04250bf656b04e39952f291e27b2951f"
      }
     },
     "ed5af00842624a979a085df9a77b44af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
