{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import efficientnet.tfkeras as efn\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from keras.layers import Dense, Flatten, Activation, Conv2D, MaxPooling2D, Dropout, Conv2D,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('gs://'):\n",
    "    print(os.path.join(dirname))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17187802288787944535\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15479566528\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11928919760620582120\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n",
      "]\n",
      "GPU Available:  True\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path)\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3)\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, target_size)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "    \n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "    def augment(img):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.image.random_saturation(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.2)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_hue(img, 0.2)\n",
    "        return img\n",
    "    \n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "    \n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "    \n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO)\n",
    "    \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables and configurations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# COMPETITION_NAME = \"ranzcr-clip-catheter-line-classification\"\n",
    "strategy = auto_select_accelerator()\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\n",
    "print(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCEPTION = False\n",
    "EFFICIENT = True\n",
    "\n",
    "if XCEPTION:\n",
    "    IMAGE_SIZE = 256#800\n",
    "    model_name = \"xception\"\n",
    "if EFFICIENT:\n",
    "    IMAGE_SIZE = 640\n",
    "    model_name = \"efficient\"\n",
    "    \n",
    "USE_TEST_FOLD = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocess CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "extras_PATH = 'gs://extras-entrenamiento/'\n",
    "datos_PATH = os.getcwd() + '/train/'#'gs://ranzcr-data/'\n",
    "df = pd.read_csv(extras_PATH + 'train_folds.csv')\n",
    "\n",
    "# paths = load_dir + \"train/\" + df['StudyInstanceUID'] + '.jpg'\n",
    "paths = datos_PATH + df['StudyInstanceUID'] + '.jpg'\n",
    "\n",
    "# sub_df = pd.read_csv(load_dir + 'sample_submission.csv')\n",
    "\n",
    "# test_paths = load_dir + \"test/\" + sub_df['StudyInstanceUID'] + '.jpg'\n",
    "# test_paths = GCS_DS_PATH + \"/test/\" + sub_df['StudyInstanceUID'] + '.jpg'\n",
    "\n",
    "# Get the multi-labels\n",
    "label_cols = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                 'Swan Ganz Catheter Present']\n",
    "labels = df[label_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds are:  [0, 1, 2, 3, 4]\n",
      "(24080, 15)\n",
      "(6003, 15)\n",
      "(23091, 15)\n",
      "(5747, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>ETT - Abnormal</th>\n",
       "      <th>ETT - Borderline</th>\n",
       "      <th>ETT - Normal</th>\n",
       "      <th>NGT - Abnormal</th>\n",
       "      <th>NGT - Borderline</th>\n",
       "      <th>NGT - Incompletely Imaged</th>\n",
       "      <th>NGT - Normal</th>\n",
       "      <th>CVC - Abnormal</th>\n",
       "      <th>CVC - Borderline</th>\n",
       "      <th>CVC - Normal</th>\n",
       "      <th>Swan Ganz Catheter Present</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>fold</th>\n",
       "      <th>fold_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.71008408169501434503...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7d2c4c9e3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.12874505746046378224...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d46ba6d06</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.36104631337783803705...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0e93aeeb4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.44301685598654680107...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4099d5872</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.37913195819499413602...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a01d16803</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    StudyInstanceUID  ETT - Abnormal  \\\n",
       "0  1.2.826.0.1.3680043.8.498.71008408169501434503...               0   \n",
       "1  1.2.826.0.1.3680043.8.498.12874505746046378224...               0   \n",
       "2  1.2.826.0.1.3680043.8.498.36104631337783803705...               0   \n",
       "3  1.2.826.0.1.3680043.8.498.44301685598654680107...               0   \n",
       "4  1.2.826.0.1.3680043.8.498.37913195819499413602...               0   \n",
       "\n",
       "   ETT - Borderline  ETT - Normal  NGT - Abnormal  NGT - Borderline  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 0             0               0                 0   \n",
       "2                 0             0               0                 0   \n",
       "3                 0             1               0                 0   \n",
       "4                 0             1               0                 0   \n",
       "\n",
       "   NGT - Incompletely Imaged  NGT - Normal  CVC - Abnormal  CVC - Borderline  \\\n",
       "0                          0             0               0                 0   \n",
       "1                          0             0               0                 0   \n",
       "2                          0             0               0                 0   \n",
       "3                          0             1               0                 0   \n",
       "4                          1             0               0                 0   \n",
       "\n",
       "   CVC - Normal  Swan Ganz Catheter Present  PatientID  fold  fold_test  \n",
       "0             1                           0  7d2c4c9e3     0         15  \n",
       "1             1                           0  d46ba6d06     0         11  \n",
       "2             1                           0  0e93aeeb4     0         14  \n",
       "3             1                           0  4099d5872     0         20  \n",
       "4             1                           0  a01d16803     0         14  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select folds here\n",
    "FOLDS_PATH = \"../input/split-k-folds/\"\n",
    "\n",
    "CURRENT_FOLD = 0# sus datos se usan para validar, el resto para entrenar\n",
    "\n",
    "dfx = pd.read_csv(os.path.join(extras_PATH, \"train_folds.csv\"))\n",
    "print(\"Folds are: \", sorted(dfx.fold.unique()))\n",
    "\n",
    "targets = [\n",
    "    \"ETT - Abnormal\",\n",
    "    \"ETT - Borderline\",\n",
    "    \"ETT - Normal\",\n",
    "    \"NGT - Abnormal\",\n",
    "    \"NGT - Borderline\",\n",
    "    \"NGT - Incompletely Imaged\",\n",
    "    \"NGT - Normal\",\n",
    "    \"CVC - Abnormal\",\n",
    "    \"CVC - Borderline\",\n",
    "    \"CVC - Normal\",\n",
    "    \"Swan Ganz Catheter Present\",\n",
    "]\n",
    "df_train = dfx[dfx.fold != CURRENT_FOLD].reset_index(drop=True)\n",
    "df_valid = dfx[dfx.fold == CURRENT_FOLD].reset_index(drop=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "\n",
    "# Para validar y asignar pesos de los modelos\n",
    "if USE_TEST_FOLD:\n",
    "    test_fold = 0\n",
    "    df_train = df_train[df_train.fold_test != test_fold].reset_index(drop=True)\n",
    "    df_valid = df_valid[df_valid.fold_test != test_fold].reset_index(drop=True)\n",
    "    print(df_train.shape)\n",
    "    print(df_valid.shape)\n",
    "\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_PATH = GCS_DS_PATH + \"/train/\"\n",
    "\n",
    "train_image_paths = [\n",
    "    os.path.join(datos_PATH, x + \".jpg\") for x in df_train.StudyInstanceUID.values\n",
    "]\n",
    "valid_image_paths = [\n",
    "    os.path.join(datos_PATH, x + \".jpg\") for x in df_valid.StudyInstanceUID.values\n",
    "]\n",
    "\n",
    "train_targets = df_train[targets].values\n",
    "valid_targets = df_valid[targets].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B7 = 600\n",
    "\n",
    "decoder = build_decoder(with_labels=True, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "test_decoder = build_decoder(with_labels=False, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "train_dataset = build_dataset(\n",
    "    train_image_paths, train_targets, bsize=BATCH_SIZE, decode_fn=decoder\n",
    ")\n",
    "\n",
    "valid_dataset = build_dataset(\n",
    "    valid_image_paths, valid_targets, bsize=BATCH_SIZE, decode_fn=decoder,\n",
    "    repeat=False, shuffle=False, augment=False\n",
    ")\n",
    "\n",
    "# test_dataset = build_dataset(\n",
    "#     test_paths, cache=False, bsize=BATCH_SIZE, decode_fn=test_decoder,\n",
    "#     repeat=False, shuffle=False, augment=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary cross-entropy is for multi-label classifications, whereas categorical cross entropy is for multi-class classification where each example belongs to a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient model B7\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "258441216/258434480 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Functional) (None, 20, 20, 2560)      64097680  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                28171     \n",
      "=================================================================\n",
      "Total params: 64,125,851\n",
      "Trainable params: 63,815,131\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if EFFICIENT:\n",
    "    n_labels = labels.shape[1]\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.Sequential([\n",
    "            efn.EfficientNetB7(\n",
    "                input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                weights='imagenet',\n",
    "                include_top=False),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            #tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "            #tf.keras.layers.PReLU(),\n",
    "            #tf.keras.layers.Dropout(rate=0.5),\n",
    "            tf.keras.layers.Dense(n_labels, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(lr=LR),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[tf.keras.metrics.AUC(multi_label=True)])\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XCEPTION Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XCEPTION:\n",
    "    \n",
    "    n_labels = labels.shape[1]\n",
    "    \n",
    "    with strategy.scope():\n",
    "        net = Xception(include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                       weights='imagenet')\n",
    "        x = net.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        #x = Dropout(0.4)(x)\n",
    "        output = Dense(n_labels, activation='sigmoid')(x)\n",
    "        model = Model(inputs=net.input, outputs=output)\n",
    "        model.compile(optimizers.Adam(lr=LR),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.AUC(multi_label=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = df_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'model_fold' + str(CURRENT_FOLD) + model_name + '.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", patience=0, min_lr=1e-6, mode='min')\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n",
    "                    restore_best_weights = True, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=10,#25\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint, lr_reducer],\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.to_csv('history_fold'+ str(CURRENT_FOLD) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation with test data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TEST_FOLD:\n",
    "    # filtramos\n",
    "    test_fold = 0\n",
    "    df_test_fold = dfx[dfx.fold_test == test_fold].reset_index(drop=True)\n",
    "    print(df_test_fold.shape)\n",
    "    # creamos el dataset\n",
    "    test_image_paths = [os.path.join(IMAGE_PATH, x + \".jpg\") for x in df_test_fold.StudyInstanceUID.values]\n",
    "    test_targets = df_test_fold[targets].values\n",
    "    test_dataset = build_dataset(test_image_paths,\n",
    "                                 test_targets,\n",
    "                                 bsize=BATCH_SIZE,\n",
    "                                 decode_fn=decoder,\n",
    "                                 repeat=False, shuffle=False, augment=False)\n",
    "    # predecimos ;)\n",
    "    y_pred = model.predict(test_dataset, verbose=1)\n",
    "    y_real = df_test_fold.iloc[:, 1:13]\n",
    "    acc_fold = np.mean([roc_auc_score(y_real.iloc[:, i], y_pred[:, i]) for i in range(11)])\n",
    "    \n",
    "    print(\"Final ACC for this fold:\", acc_fold)\n",
    "    \n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "    loss = np.mean([bce(y_real.iloc[:, i], y_pred[:, i]) for i in range(11)])\n",
    "    print('Loss: ', loss.numpy()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
